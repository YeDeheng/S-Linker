Minor	O
:	O
`	O
notnull	B-API
`	O
is	O
also	O
a	O
method	O
of	O
DataFrames	O
.	O

I	O
want	O
to	O
apply	O
a	O
function	O
f	O
(	O
lat1	O
,	O
lon1	O
,	O
lat2	O
,	O
lon2	O
)	O
which	O
calculates	O
the	O
distance	O
between	O
two	O
points	O
(	O
defined	O
using	O
lat1	O
,	O
lon1	O
,	O
lat2	O
,	O
lon2	O
)	O
.	O

For	O
all	O
110k+	O
records	O
in	O
`	O
df1	O
`	O
do	O
you	O
want	O
to	O
apply	O
your	O
distance	O
function	O
for	O
every	O
record	O
in	O
`	O
df2	O
`	O
?	O

I	O
chose	O
to	O
use	O
map	B-API
and	O
list	O
comprehensions	O
because	O
they	O
will	O
be	O
faster	O
than	O
a	O
standard	O
`	O
for	O
each	O
`	O

However	O
I	O
took	O
this	O
into	O
account	O
and	O
used	O
map	B-API
,	O
and	O
nested	O
comprehensions	O
which	O
are	O
going	O
to	O
be	O
faster	O
than	O
a	O
for	O
loop	O
.	O

Keep	O
getting	O
:	O
KeyError	O
:	O
'	O
cannot	O
use	O
a	O
single	O
bool	O
to	O
index	O
into	O
setitem	O
'	O
on	O
this	O
line	O
of	O
code	O
in	O
the	O
second	O
chunk	O
I	O
posted	O
.	O

i	O
have	O
to	O
merge	O
them	O
in	O
to	O
the	O
same	O
cell	O
before	O
applying	O
this	O
method	O
.	O

Or	O
is	O
there	O
are	O
way	O
to	O
marge	O
the	O
columns	O
in	O
pandas	O
?	O

I	O
have	O
two	O
TimeSeries	O
with	O
some	O
overlapping	O
dates	O
/	O
indices	O
and	O
I'd	O
like	O
to	O
merge	O
them	O
.	O

I	O
have	O
an	O
excel	O
file	O
(	O
.xls	O
format	O
)	O
with	O
5	O
sheets	O
,	O
I	O
want	O
to	O
replace	O
the	O
contents	O
of	O
sheet	O
5	O
with	O
contents	O
of	O
my	O
pandas	O
data	O
frame	O
.	O

So	O
,	O
I	O
decided	O
to	O
do	O
this	O
task	O
in	O
VBA	O
and	O
drop	O
python	O
completely	O
.	O

It	O
could	O
be	O
I'm	O
not	O
using	O
the	O
right	O
keywords	O
,	O
so	O
if	O
you	O
have	O
suggestions	O
,	O
that	O
could	O
also	O
help	O
.	O

plus	O
the	O
selected	O
rows	O
usage	O
x	O
2	O
,	O
which	O
will	O
happen	O
when	O
you	O
concat	O
the	O
rows	O

after	O
the	O
concat	B-API
the	O
usage	O
will	O
go	O
down	O
to	O
selected	O
rows	O
usage	O

See	O
example	O
here	O
:	O
#URL	O
Not	O
sure	O
this	O
will	O
solve	O
it	O
,	O
but	O
that	O
will	O
do	O
the	O
query	O
in	O
chunks	O
,	O
and	O
you	O
can	O
aggregate	O
or	O
merge	O
them	O
in	O
pandas	O

Try	O
a	O
`	O
dropna	B-API
`	O
or	O
use	O
`	O
missing=	O
'	O
drop	O
'`	O
to	O
Logit	O
.	O

You	O
might	O
also	O
check	O
that	O
the	O
right	O
hand	O
side	O
is	O
full	O
rank	O
`	O
np.linalg.matrix_rank	B-API
(	O
data	O
[	O
train_cols	O
]	O
.values	B-API
)`	O

append	O
pandas.DataFrame.GroupBy	B-API
results	O
into	O
another	O
dataframe	O

You	O
need	O
to	O
append	O
the	O
intermediate	O
DataFrames	O
to	O
a	O
list	O
and	O
then	O
concatenate	O
the	O
results	O
.	O

I	O
am	O
taking	O
the	O
second	O
dataframe	O
and	O
doing	O
some	O
calculations	O
with	O
it	O
to	O
append	O
to	O
the	O
first	O
dataframe	O
.	O

However	O
it	O
does	O
not	O
appear	O
that	O
what	O
I	O
am	O
appending	O
to	O
the	O
first	O
data	O
frame	O
is	O
actually	O
happening	O
.	O

Could	O
you	O
use	O
concat	B-API
instead	O
?	O

`	O
m=	O
m.concat	O
([	O
a0	O
,	O
a1	O
,	O
a2	O
,	O
a3	O
,	O
a4	O
,	O
a5	O
,	O
a6	O
,	O
a7	O
,	O
a8	O
,	O
a9	O
]	O
,	O
ignore_index=True	O
)`	O

I	O
get	O
an	O
error	O
trying	O
to	O
use	O
this	O
...	O

AttributeError	O
:	O
'	O
DataFrame	O
'	O
object	O
has	O
no	O
attribute	O
'	O
concat	B-API
'	O

[	O
`	O
append	B-API
`]	O
(	O
#URL	O
)	O
does	O
*	O
not	O
*	O
operate	O
in	O
place	O
.	O

But	O
for	O
a	O
start	O
I	O
would	O
just	O
be	O
happy	O
to	O
get	O
the	O
first	O
result	O
.	O

I	O
suspect	O
that	O
I	O
need	O
to	O
use	O
searchsort	O
and	O
asof	B-API
,	O
but	O
I	O
am	O
not	O
quite	O
sure	O
how	O
to	O
do	O
that	O
with	O
.	O

You're	O
looking	O
for	O
a	O
near	O
timestamp	O
,	O
where	O
`	O
asof	B-API
`	O
searches	O
for	O
the	O
latest	O
timestamp	O
.	O

It	O
is	O
only	O
applied	O
to	O
a	O
time	O
series	O
,	O
so	O
you	O
would	O
have	O
to	O
apply	O
`	O
reset_index	B-API
`	O
to	O
your	O
`	O
DataFrame	O
`	O

You're	O
going	O
to	O
have	O
to	O
iterate	O
over	O
your	O
list	O
,	O
get	O
copies	O
of	O
them	O
filtered	O
and	O
then	O
concat	O
them	O
all	O
together	O
#CODE	O

A	O
solution	O
without	O
loop	O
but	O
`	O
merge	B-API
`	O
:	O
#CODE	O

If	O
there	O
are	O
no	O
blanks	O
some	O
columns	O
convert	O
to	O
`	O
TRUE	O
/	O
FALSE	O
`	O
,	O
others	O
leave	O
as	O
`	O
Yes	O
/	O
No	O
`	O
but	O
dtype	B-API
is	O
bool	B-API
.	O

`	O
fhs	O
=	O
fhs.drop	O
([	O
1002	O
])`	O
to	O
drop	O
that	O
row	O
and	O
data	O
types	O
are	O
still	O
good	O
.	O

first	O
column	O
comes	O
into	O
df	O
as	O
Yes	O
,	O
No	O
,	O
Yes	O
,	O
Yes	O
type	O
bool	O
xxxx	O
below	O

3rd	O
column	O
comes	O
into	O
df	O
as	O
FALSE	O
,	O
FALSE	O
,	O
TRUE	O
,	O
TRUE	O
type	O
bool	O

print	O
(	O
len	B-API
(	O
upregulated	O
)	O
,	O
end=	O
'	O
\n	O
')	O

remove	O
overlay	O
text	O
from	O
pandas	O
boxplot	O

I	O
am	O
trying	O
to	O
remove	O
the	O
overlay	O
text	O
on	O
my	O
boxplot	O
I	O
created	O
using	O
pandas	O
.	O

The	O
code	O
to	O
generate	O
it	O
is	O
as	O
follows	O
(	O
minus	O
a	O
few	O
other	O
modifications	O
):	O

I	O
just	O
want	O
to	O
remove	O
the	O
"	O
boxplot	O
grouped	O
by	O
0	O
...	O

I	O
know	O
how	O
to	O
create	O
a	O
new	O
column	O
with	O
`	O
apply	B-API
`	O
or	O
`	O
np.where	B-API
`	O
based	O
on	O
the	O
values	O
of	O
another	O
column	O
,	O
but	O
a	O
way	O
of	O
selectively	O
changing	O
the	O
values	O
of	O
an	O
existing	O
column	O
is	O
escaping	O
me	O
;	O
I	O
suspect	O
`	O
df.ix	B-API
`	O
is	O
involved	O
?	O

@USER	O
For	O
indexing	O
with	O
boolean	O
vectors	O
this	O
is	O
perfectly	O
fine	O
,	O
if	O
you	O
want	O
to	O
add	O
in	O
other	O
forms	O
of	O
indexing	O
you	O
would	O
want	O
`	O
loc	B-API
`	O
.	O

For	O
instance	O
:	O
`	O
df.loc	B-API
[	O
df.name.str.contains	O
(	O
'	O
e$	O
')	O
,	O
'	O
flag	O
']	O
=	O
'	O
Blue	O
'`	O
.	O

use	O
``	O
apply	B-API
``	O
ONLY	O
as	O
a	O
last	O
resort	O
(	O
e.g.	O
you	O
can't	O
do	O
vectorized	O
things	O
)	O
.	O
even	O
if	O
you	O
have	O
a	O
very	O
complicated	O
function	O
to	O
do	O
,	O
you	O
can	O
often	O
do	O
vectorized	O
calculations	O
on	O
most	O
of	O
it	O
,	O
saving	O
the	O
last	O
for	O
``	O
apply	B-API
``	O
,	O
which	O
is	O
essentially	O
a	O
loop	O
.	O

Using	O
apply	B-API
took	O
172ms	O
versus	O
39ms	O
using	O
Jeff's	O
method	O
,	O
I	O
can	O
also	O
confirm	O
that	O
it	O
made	O
negligle	O
difference	O
whether	O
the	O
apply	B-API
was	O
called	O
inside	O
or	O
outside	O
the	O
function	O
but	O
it	O
does	O
modify	O
the	O
df	O
so	O
you	O
didn't	O
need	O
to	O
return	O
the	O
df	O
as	O
it	O
was	O
being	O
modified	O
inside	O
the	O
function	O

And	O
then	O
sometimes	O
different	O
solutions	O
(	O
in	O
this	O
case	O
using	O
`	O
apply	B-API
`)	O
come	O
up	O
on	O
google	O
/	O
stackoverflow	O
and	O
yet	O
again	O
I	O
can	O
NOT	O
verify	O
that	O
there	O
is	O
no	O
better	O
solution	O
as	O
I	O
dont	O
have	O
the	O
insight	O
into	O
the	O
library	O
.	O

I	O
kindof	O
disagree	O
with	O
using	O
df	O
as	O
the	O
variable	O
name	O
here	O
,	O
I	O
also	O
think	O
I'd	O
just	O
use	O
len	B-API
:	O
`	O
df.groupby	B-API
(	O
"	O
Name	O
")	O
.filter	B-API
(	O
lambda	O
x	O
:	O
len	B-API
(	O
x	O
)	O
>	O
2	O
)`	O

Merge	O
existing	O
dataframe	O
into	O
fixed	O
size	O
new	O
dataframe	O

Then	O
I	O
want	O
merge	B-API
these	O
kinds	O
of	O
table	O
into	O
new	O
dataframe	O

How	O
could	O
I	O
merge	O
them	O
in	O
that	O
way	O
?	O

Inconsistent	O
behavior	O
of	O
apply	B-API
with	O
operator.itemgetter	O
v.s.	O
applymap	B-API
operator.itemgetter	O

`	O
apply	B-API
`	O
gives	O
wrong	O
result	O
#CODE	O

apply	B-API
is	O
being	O
passed	O
an	O
entire	O
row	O
which	O
is	O
a	O
series	O
of	O
2	O
elements	O
which	O
are	O
lists	O
;	O
the	O
last	O
list	O
is	O
returned	O
and	O
coerced	O
to	O
a	O
series	O
.	O
embedded	O
lists	O
as	O
elements	O
are	O
not	O
a	O
good	O
idea	O
in	O
general	O
.	O

The	O
reason	O
I	O
am	O
asking	O
,	O
is	O
because	O
I	O
suspect	O
(	O
?	O
)	O
it	O
is	O
faster	O
to	O
create	O
a	O
zero	O
filled	O
dataframe	O
,	O
and	O
then	O
replace	O
each	O
element	O
as	O
needed	O
.	O

So	O
it	O
might	O
be	O
faster	O
to	O
create	O
an	O
empty	O
dataframe	O
with	O
nxm	O
dimensions	O
and	O
then	O
replace	O
elements	O
as	O
needed	O
(	O
by	O
copying	O
a	O
list	O
to	O
each	O
column	O
)	O
.	O

in	O
general	O
creating	O
an	O
empty	O
frame	O
,	O
then	O
filling	O
it	O
column	O
by	O
column	O
is	O
not	O
very	O
efficient	O
;	O
use	O
a	O
dict	O
/	O
list	O
instead	O
,	O
or	O
create	O
sub-frames	O
and	O
concat	O
them	O

Are	O
you	O
trying	O
to	O
shift	O
ends	O
by	O
one	O
(	O
month	O
)	O
?	O

My	O
initial	O
suggestion	O
was	O
to	O
do	O
the	O
shift	B-API
after	O
you've	O
reindexed	O
(	O
since	O
you're	O
about	O
to	O
do	O
that	O
anyway	O
):	O
#CODE	O

the	O
shift	B-API
index	O
looks	O
like	O
a	O
better	O
fix	O
,	O
still	O
would	O
like	O
to	O
know	O
if	O
there	O
is	O
a	O
simple	O
date	O
add	O
function	O
,	O
which	O
is	O
how	O
I'd	O
do	O
it	O
in	O
sql	O
,	O
that	O
could	O
apply	O
?	O

I'd	O
still	O
like	O
to	O
know	O
if	O
there	O
is	O
a	O
simple	O
DateAdd	O
type	O
function	O
that	O
I	O
could	O
use	O
that	O
might	O
also	O
apply	O
for	O
use	O
elsewhere	O
if	O
needed	O
?	O

Alternatively	O
you	O
could	O
use	O
`	O
apply	B-API
`	O
(	O
but	O
this	O
will	O
usually	O
be	O
slower	O
):	O
#CODE	O

Since	O
you	O
are	O
using	O
the	O
"	O
trailing	O
row	O
"	O
you	O
are	O
going	O
to	O
need	O
to	O
use	O
`	O
shift	B-API
`	O
:	O
#CODE	O

thanks	O
shift	B-API
is	O
what	O
i	O
was	O
looking	O
for	O
.	O
now	O
i	O
can	O
find	O
examples	O
in	O
the	O
Pandas	O
book	O

I	O
have	O
been	O
searching	O
for	O
hours	O
,	O
literally	O
the	O
entire	O
day	O
on	O
how	O
to	O
generate	O
a	O
pivot	O
table	O
in	O
Python	O
.	O

What	O
I	O
want	O
is	O
to	O
take	O
a	O
csv	O
file	O
,	O
extract	O
the	O
first	O
column	O
and	O
generate	O
a	O
pivot	O
table	O
using	O
the	O
count	O
or	O
frequency	O
of	O
the	O
numbers	O
in	O
that	O
column	O
,	O
and	O
sort	O
descending	O
#CODE	O

These	O
columns	O
all	O
contain	O
an	O
identical	O
kind	O
of	O
data	O
,	O
and	O
I'd	O
like	O
to	O
stack	O
them	O
into	O
a	O
single	O
series	O
,	O
ergo	O
:	O
#CODE	O

From	O
here	O
,	O
I	O
can't	O
quite	O
figure	O
out	O
how	O
to	O
reindex	O
my	O
series	O
such	O
that	O
the	O
indexes	O
go	O
from	O
0	O
to	O
`	O
len	B-API
(	O
s	O
)`	O
.	O

But	O
it	O
could	O
be	O
an	O
unexpected	O
system	O
difference	O
--	O
I	O
am	O
using	O
Python	O
2.7.3	O
on	O
an	O
Ubuntu	O
machine	O
.	O

An	O
alternative	O
you	O
might	O
try	O
is	O
to	O
replace	O
exit()	O
with	O
os._exit	O
(	O
os.EX_OK	O
)	O
.	O

I	O
think	O
it	O
uses	O
`	O
patsy	O
`	O
in	O
the	O
backend	O
to	O
translate	O
the	O
formula	O
expression	O
,	O
and	O
intercept	O
is	O
added	O
automatically	O
.	O

Trying	O
to	O
append	O
this	O
to	O
a	O
new	O
datastore	O
.	O

The	O
datastore	O
does	O
not	O
exist	O
so	O
I	O
use	O
the	O
following	O
to	O
create	O
and	O
append	O
the	O
data	O
;	O
#CODE	O

I'm	O
not	O
looking	O
to	O
concatenate	O
strings	O
,	O
just	O
shift	O
everything	O
over	O
.	O

I	O
saw	O
a	O
method	O
using	O
"	O
R	O
"	O
and	O
melt	B-API
,	O
however	O
I	O
would	O
like	O
to	O
stick	O
with	O
python	O
/	O
pandas	O
if	O
possible	O
.	O

I	O
cannot	O
post	O
real	O
request	O
for	O
security	O
reason	O
.	O

By	O
the	O
way	O
the	O
code	O
works	O
without	O
"	O
append	B-API
"	O
within	O
for	O
loop	O
.	O

At	O
first	O
I	O
tried	O
using	O
pivot	B-API
(	O
with	O
timestamp	O
as	O
an	O
index	O
)	O
,	O
but	O
that	O
didn't	O
work	O
because	O
of	O
those	O
duplicates	O
.	O

I	O
don't	O
want	O
to	O
drop	O
them	O
,	O
since	O
the	O
other	O
data	O
is	O
different	O
and	O
should	O
not	O
be	O
lost	O
.	O

Since	O
index	O
contains	O
no	O
duplicates	O
,	O
I	O
thought	O
maybe	O
I	O
can	O
pivot	O
over	O
it	O
and	O
after	O
that	O
merge	O
the	O
result	O
into	O
the	O
original	O
DataFrame	O
,	O
but	O
I	O
was	O
wondering	O
if	O
there	O
is	O
an	O
easier	O
more	O
intuitive	O
solution	O
.	O

As	O
your	O
`	O
get_dummies	B-API
`	O
returns	O
a	O
df	O
this	O
will	O
be	O
aligned	O
already	O
with	O
your	O
existing	O
df	O
so	O
just	O
`	O
concat	B-API
`	O
column-wise	O
:	O
#CODE	O

You	O
can	O
drop	O
the	O
'	O
cat	O
'	O
column	O
by	O
doing	O
`	O
df.drop	B-API
(	O
'	O
cat	O
'	O
,	O
axis=1	O
)`	O

You	O
can	O
see	O
that	O
the	O
array	O
is	O
masked	O
and	O
that	O
some	O
of	O
the	O
first	O
few	O
rows	O
show	O
examples	O
of	O
`	O
--	O
`	O
in	O
there	O
.	O

So	O
I	O
drop	O
the	O
last	O
field	O
(	O
`	O
refGage	O
`)	O
and	O
it	O
works	O
,	O
so	O
I	O
think	O
it's	O
masked	O
values	O
which	O
only	O
appear	O
in	O
that	O
field	O
.	O

I	O
used	O
df.ix()	B-API
to	O
replace	O
the	O
filled-in	O
tokens	O
for	O
what	O
was	O
masked	O
out	O
.	O

Next	O
,	O
you	O
can	O
use	O
a	O
dictionary	O
comprehension	O
together	O
with	O
`	O
loc	B-API
`	O
to	O
select	O
the	O
relevant	O
`	O
group_no	O
`	O
dataframe	O
.	O

To	O
get	O
the	O
last	O
group	O
number	O
,	O
I	O
get	O
the	O
last	O
value	O
using	O
`	O
iat	B-API
`	O
for	O
location	O
based	O
indexing	O
.	O

Then	O
apply	O
your	O
method	O
:	O
#CODE	O

Notice	O
that	O
if	O
you	O
unstack	B-API
the	O
`	O
id	O
`	O
index	O
level	O
of	O
`	O
df	O
`	O
then	O
you	O
get	O
:	O
#CODE	O

I'm	O
not	O
used	O
to	O
working	O
with	O
`	O
lists	O
`	O
in	O
columns	O
of	O
Pandas	O
and	O
don't	O
know	O
how	O
to	O
get	O
the	O
intersection	O
of	O
`	O
lists	O
`	O
from	O
two	O
columns	O
in	O
a	O
`	O
dataframe	O
`	O
,	O
then	O
get	O
the	O
index	O
of	O
where	O
the	O
words	O
appear	O
,	O
then	O
apply	O
plus	O
signs	O
to	O
the	O
front	O
of	O
each	O
found	O
index	O
.	O

Or	O
maybe	O
easier	O
would	O
be	O
a	O
string	O
replacement	O
on	O
`	O
df	O
[	O
'	O
Keyword	O
']`	O
using	O
the	O
words	O
from	O
`	O
StemmedAG	O
`	O
?	O

You	O
can	O
use	O
`	O
pivot	B-API
`	O
#CODE	O

Cool	O
I	O
didn't	O
know	O
about	O
pivot	B-API
either	O
...	O

Instead	O
of	O
creating	O
it	O
,	O
we	O
can	O
append	O
it	O
to	O
initial	O
StartDate	O
.	O

However	O
,	O
the	O
DptCityDptCountry	O
might	O
be	O
different	O
but	O
if	O
another	O
ID	O
matches	O
with	O
the	O
StartDate	O
and	O
DptCityDptCountry	O
,	O
it	O
will	O
be	O
added	O
up	O
i.e.	O
#CODE	O

Then	O
use	O
apply	B-API
and	O
return	O
a	O
series	O
indexed	O
on	O
the	O
expanded	O
set	O
of	O
dates	O
for	O
each	O
row	O
(	O
Series	O
of	O
Series	O
=	O
DataFrame	O
)	O
.	O

So	O
for	O
each	O
of	O
the	O
7	O
rows	O
in	O
the	O
DataFrame	O
,	O
I	O
get	O
a	O
series	O
indexed	O
on	O
the	O
expanded	O
date	O
range	O
.	O

Then	O
its	O
just	O
clever	O
stacking	O
,	O
naming	O
,	O
and	O
reset_index	B-API
.	O

Also	O
,	O
if	O
you	O
want	O
to	O
have	O
the	O
ticklabels	O
/	O
tickmarks	O
of	O
the	O
x-axis	O
connected	O
to	O
the	O
"	O
middle	O
axis	O
"	O
(	O
also	O
while	O
panning	O
/	O
zooming	O
)	O
,	O
then	O
it's	O
easiest	O
to	O
insert	O
an	O
extra	O
spine	O
;	O
take	O
a	O
look	O
at	O
[	O
`	O
mpl_toolkits.axisartist	B-API
`]	O
(	O
#URL	O
)	O
for	O
some	O
examples	O
of	O
this	O
.	O

print	O
(	O
'	O
Stock	O
:	O
'	O
,	O
col	O
,	O
'	O
max	O
diff	B-API
:	O
'	O
,	O
sl.max()	O
-	O
sl.min()	O
)`	O

Then	O
merge	O
back	O
to	O
the	O
original	O
dataframe	O
to	O
have	O
your	O
aggregates	O
displayed	O
against	O
each	O
row	O
:	O
#CODE	O

Unfortunately	O
im	O
getting	O
an	O
issue	O
when	O
trying	O
to	O
do	O
the	O
rename	O
.	O

The	O
true	O
/	O
false	O
column	O
does	O
not	O
have	O
a	O
column	O
name	O
,	O
so	O
how	O
would	O
I	O
rename	O
it	O
and	O
then	O
merge	O
it	O
back	O
into	O
the	O
original	O
dataframe	O
?	O

I	O
am	O
using	O
the	O
below	O
code	O
which	O
gives	O
me	O
the	O
summary	O
of	O
count	O
in	O
the	O
pivot	O
table	O
,	O
#CODE	O

but	O
what	O
i	O
want	O
is	O
the	O
%	O
of	O
row	O
calculation	O
as	O
in	O
excel	O
pivot	O
when	O
you	O
right	O
click	O
the	O
pivot	O
and	O
select	O
"	O
show	O
value	O
as	O
->	O
%	O
of	O
Row	O
Total	O
"	O
.	O

Since	O
my	O
Document	O
is	O
a	O
non-numeric	O
value	O
i	O
was	O
not	O
able	O
to	O
get	O
it	O
.	O

i	O
am	O
trying	O
to	O
manipulate	O
the	O
pivot	O
data	O
which	O
will	O
give	O
me	O
the	O
row	O
total	O
,	O
not	O
the	O
data	O
from	O
the	O
dataframe	O
and	O
what	O
i	O
wanted	O
is	O
"	O
%	O
of	O
row	O
total	O
"	O
.	O

you	O
can	O
actually	O
just	O
pass	O
`	O
aggfunc=len	O
`	O
,	O
since	O
`	O
len	B-API
`	O
is	O
already	O
a	O
function	O
:)	O

Hi	O
maxymoo	O
in	O
the	O
link	O
you	O
have	O
given	O
they	O
are	O
manipulating	O
one	O
of	O
the	O
column	O
from	O
the	O
dataframe	O
,	O
but	O
my	O
question	O
is	O
different	O
i	O
am	O
trying	O
to	O
manipulate	O
the	O
pivot	O
data	O
which	O
will	O
give	O
me	O
the	O
row	O
total	O
and	O
what	O
i	O
wanted	O
is	O
"	O
%	O
of	O
row	O
total	O
"	O
.	O

Then	O
you	O
can	O
basically	O
use	O
the	O
solution	O
@USER	O
linked	O
to	O
,	O
but	O
you	O
need	O
to	O
use	O
`	O
iloc	B-API
`	O
or	O
similar	O
b	O
/	O
c	O
the	O
table	O
columns	O
are	O
a	O
little	O
complicated	O
now	O
(	O
being	O
a	O
multi-indexed	O
result	O
of	O
the	O
pivot	O
table	O
)	O
.	O

Unfortunately	O
,	O
if	O
I	O
try	O
to	O
resample	O
,	O
I	O
get	O
an	O
error	O
#CODE	O

Are	O
you	O
ask	O
for	O
a	O
process	O
to	O
interpolate	O
,	O
or	O
a	O
process	O
to	O
aggregate	O
,	O
or	O
both	O
?	O

Firstly	O
,	O
prepare	O
a	O
function	O
to	O
map	O
the	O
day	O
to	O
week	O
#CODE	O

Assume	O
now	O
your	O
initialized	O
new	O
dataframe	O
is	O
`	O
result	O
`	O
,	O
you	O
can	O
now	O
do	O
a	O
join	B-API
#CODE	O

The	O
`	O
Nan	O
`	O
is	O
what	O
you	O
need	O
to	O
interpolate	O
.	O

Turns	O
out	O
the	O
key	O
is	O
to	O
resample	O
a	O
groupby	B-API
object	O
like	O
so	O
:	O
#CODE	O

Then	O
,	O
I	O
append	O
a	O
row	O
of	O
missing	O
values	O
.	O

Finally	O
,	O
I	O
can	O
insert	O
values	O
into	O
this	O
DataFrame	O
one	O
cell	O
at	O
a	O
time	O
.	O

This	O
approach	O
works	O
perfectly	O
fine	O
,	O
with	O
the	O
exception	O
that	O
the	O
append	B-API
statement	O
inserts	O
an	O
additional	O
column	O
to	O
my	O
DataFrame	O
.	O

The	O
append	B-API
is	O
trying	O
to	O
append	O
a	O
column	O
to	O
your	O
dataframe	O
.	O

The	O
column	O
it	O
is	O
trying	O
to	O
append	B-API
is	O
not	O
named	O
and	O
has	O
two	O
None	O
/	O
Nan	O
elements	O
in	O
it	O
which	O
pandas	O
will	O
name	O
(	O
by	O
default	O
)	O
as	O
column	O
named	O
0	O
.	O

In	O
order	O
to	O
do	O
this	O
successfully	O
,	O
the	O
column	O
names	O
coming	O
into	O
the	O
append	B-API
for	O
the	O
data	O
frame	O
must	O
be	O
consistent	O
with	O
the	O
current	O
data	O
frame	O
column	O
names	O
or	O
else	O
new	O
columns	O
will	O
be	O
created	O
(	O
by	O
default	O
)	O
#CODE	O

have	O
merged	O
2	O
dataframes	O
with	O
left	O
join	B-API
.	O
works	O
as	O
I	O
expected	O
until	O
I	O
attempt	O
to	O
use	O
the	O
generated	O
value	O
in	O
a	O
simple	O
string	O
concatenation	O
.	O

I	O
am	O
ultimately	O
trying	O
to	O
merge	O
two	O
dataframes	O
together	O
,	O
but	O
I	O
am	O
running	O
into	O
an	O
issue	O
when	O
I	O
try	O
to	O
specify	O
the	O
column	O
on	O
which	O
they	O
should	O
be	O
merged	O
.	O

Conform	O
the	O
index	O
to	O
another	O
frequency	O
.	O

Then	O
its	O
straightforward	O
to	O
resample	O
to	O
another	O
frequency	O
.	O

In	O
the	O
second	O
chunk	O
you	O
are	O
resampling	O
and	O
the	O
result	O
is	O
a	O
Series	O
of	O
monthly	O
frequency	O
so	O
it	O
would	O
appear	O
that	O
the	O
daily	O
information	O
is	O
lost	O
.	O

Then	O
you	O
resample	O
and	O
somehow	O
the	O
days	O
are	O
there	O
?	O

I	O
want	O
to	O
use	O
a	O
combination	O
of	O
map	B-API
&	O
lambda	O
functions	O
to	O
do	O
this	O

the	O
map	B-API
function	O
does	O
not	O
append	O
to	O
NN	O
.	O

Have	O
you	O
tried	O
using	O
`	O
concat	B-API
`	O
and	O
a	O
generator	O
expression	O
instead	O
:	O
#CODE	O

Can	O
Pandas	O
find	O
all	O
the	O
lines	O
that	O
join	O
any	O
pair	O
of	O
dots	O
and	O
don't	O
intersect	O
any	O
of	O
the	O
given	O
lines	O
without	O
iteration	O
?	O

I'm	O
a	O
Stata	O
user	O
and	O
in	O
Stata	O
,	O
I'd	O
be	O
using	O
replace	B-API
command	O
conditional	O
on	O
regexm	O
.	O

I'm	O
trying	O
to	O
learn	O
Python	O
and	O
it's	O
been	O
a	O
difficult	O
journey	O
!	O

We	O
then	O
apply	O
another	O
function	O
to	O
this	O
that	O
converts	O
the	O
str	O
numbers	O
to	O
ints	O
,	O
puts	O
these	O
in	O
a	O
list	O
and	O
returns	O
the	O
smallest	O
value	O
:	O
#CODE	O

this	O
is	O
an	O
approach	O
that	O
I	O
hadn't	O
thought	O
about	O
and	O
one	O
that	O
I'm	O
likely	O
to	O
employ	O
down	O
the	O
road	O
.	O
for	O
age	O
,	O
I	O
wanted	O
the	O
series	O
[	O
62	O
,	O
55	O
,	O
67	O
]	O
at	O
the	O
end	O
,	O
and	O
the	O
problem	O
I'm	O
having	O
now	O
is	O
that	O
I	O
can't	O
target	O
just	O
row2	O
when	O
I	O
apply	O
split	B-API
(	O
'	O
')	O
.	O

return	O
min	B-API
(	O
list	O
(	O
map	B-API
(	O
int	O
,	O
x	O
)))`	O
to	O
`	O
def	O
highest	O
(	O
x	O
):	O

return	O
max	B-API
(	O
list	O
(	O
map	B-API
(	O
int	O
,	O
x	O
)))`	O

I	O
want	O
to	O
apply	O
df	O
[	O
'	O
age	O
']	O
=d	O
f	O
[	O
'	O
e0	O
']	O
[(	O
df	O
[	O
'	O
e0	O
']	O
.str	B-API
.match	B-API
(	O
pattern7	O
)=	O
=1	O
)]	O
.apply	B-API
(	O
lambda	O
x	O
:	O
str	O
(	O
x	O
)	O
.split	B-API
(	O
'	O
')	O
[	O
1	O
])	O
to	O
only	O
rows	O
for	O
which	O
df	O
[	O
'	O
e0	O
']	O
.str	B-API
.match	B-API
(	O
pattern7	O
)=	O
=1	O
)	O
so	O
as	O
to	O
not	O
overwrite	O
what	O
was	O
already	O
in	O
the	O
age	O
column	O
...	O

Suppose	O
I	O
have	O
two	O
DataFrames	O
a	O
b	O
where	O
a	O
is	O
larger	O
than	O
b	O
and	O
has	O
all	O
NaNs	O
.	O

I	O
wish	O
to	O
merge	O
the	O
values	O
from	O
b	O
into	O
a	O
.	O

the	O
w	O
variable	O
will	O
not	O
surpass	O
len	B-API
(	O
seq	O
)	O
.	O

For	O
example	O
instead	O
of	O
looping	O
trough	O
every	O
element	O
in	O
a	O
numpy	O
array	O
to	O
do	O
some	O
processing	O
you	O
can	O
apply	O
a	O
numpy	O
function	O
directly	O
on	O
the	O
array	O
and	O
get	O
the	O
results	O
in	O
seconds	O
rather	O
than	O
hours	O
.	O
as	O
an	O
example	O
:	O
#CODE	O

Computing	O
`	O
len	B-API
(	O
seq	O
)`	O
inside	O
the	O
loop	O
is	O
not	O
necessary	O
,	O
since	O
its	O
value	O
is	O
not	O
changing	O
.	O

You	O
don't	O
really	O
need	O
the	O
`	O
if	O
`	O
statement	O
,	O
since	O
in	O
your	O
code	O
it	O
always	O
evaluate	O
to	O
true	O
(	O
`	O
w	O
in	O
range	O
(	O
len	B-API
(	O
seq	O
))`	O
means	O
`	O
w	O
`	O
maximium	O
value	O
will	O
be	O
`	O
len	B-API
(	O
seq	O
)	O
-1	O
`)	O
.	O

I	O
tried	O
pivot	B-API
but	O
it	O
returns	O
an	O
error	O

Hmm	O
My	O
dataframe	O
had	O
12	O
rows	O
but	O
when	O
i	O
tried	O
the	O
unstack	B-API
operation	O
the	O
resulting	O
dataframe	O
has	O
only	O
6	O
rows	O
not	O
exactly	O
what	O
i	O
want.My	O
resulting	O
dataframe	O
should	O
also	O
have	O
12	O
rows	O

For	O
example	O
,	O
say	O
`	O
Jul-03	O
`	O
data	O
,	O
row	O
`	O
0	O
,	O
6	O
,	O
9	O
`	O
are	O
all	O
records	O
about	O
the	O
same	O
`	O
snapDate	O
`	O
with	O
instance	O
`	O
XX	O
`	O
.	O

So	O
doing	O
a	O
pivot	B-API
would	O
reshape	O
these	O
3	O
rows	O
to	O
only	O
one	O
row	O
because	O
those	O
data	O
have	O
been	O
moved	O
to	O
columns	O
.	O

Hi	O
I	O
went	O
ahead	O
and	O
changed	O
the	O
datatype	O
of	O
AvgWaitInMs	O
to	O
int	O
and	O
the	O
pivot	B-API
worked	O

What	O
I	O
would	O
like	O
to	O
do	O
is	O
slice	O
each	O
group	O
down	O
to	O
3	O
hours	O
max	O
and	O
append	O
something	O
to	O
the	O
6	O
and	O
9	O
length	O
groups	O
to	O
denote	O
that	O
it	O
is	O
the	O
same	O
page	O
like	O
the	O
following	O
:	O
#CODE	O

So	O
,	O
I	O
truncated	O
my	O
data	O
set	O
in	O
the	O
question	O
to	O
make	O
it	O
easier	O
to	O
read	O
and	O
thinking	O
that	O
whatever	O
solution	O
came	O
would	O
also	O
apply	O
..	O

If	O
'	O
data	O
'	O
is	O
a	O
pd.DataFrame	B-API
and	O
you	O
iterate	O
over	O
range	O
(	O
0	O
,	O
len	B-API
(	O
data	O
))	O
and	O
then	O
add	O
data	O
to	O
your	O
list	O
'	O
all_info	O
'	O
,	O
you	O
simply	O
add	O
the	O
whole	O
DataFrame	O
'	O
data	O
'	O
i	O
times	O
to	O
the	O
list	O
.	O

Python	O
pandas	O
:	O
retrieve	O
the	O
field	O
associated	O
to	O
the	O
min	O
of	O
another	O
(	O
cross	O
apply	O
equivalent	O
)	O

In	O
SQL	O
I	O
was	O
used	O
to	O
doing	O
this	O
with	O
a	O
cross	O
apply	O
.	O

PS	O
other	O
than	O
calculating	O
the	O
min	O
first	O
,	O
then	O
doing	O
a	O
join	B-API
on	O
primary	O
key	O
and	O
date	O

I	O
can	O
do	O
this	O
in	O
two	O
steps	O
:	O
1	O
)	O
group	O
by	O
primary	O
key	O
and	O
calculate	O
min	O
(	O
date	O
)	O
2	O
)	O
do	O
an	O
inner	O
join	B-API
between	O
the	O
starting	O
table	O
and	O
the	O
table	O
calculated	O
in	O
the	O
previous	O
step	O
,	O
on	O
primary	O
key	O
and	O
date	O
,	O
to	O
retrieve	O
the	O
amount	O

Call	O
`	O
resample	B-API
`	O
and	O
pass	O
the	O
rule	O
as	O
'	O
10Min	O
'	O
:	O
#CODE	O

The	O
quickest	O
way	O
I	O
know	O
how	O
to	O
wrangle	O
this	O
thing	O
into	O
a	O
long	O
form	O
dataframe	O
is	O
using	O
`	O
stack	B-API
`	O
and	O
then	O
`	O
reset_index	B-API
`	O
:	O
#CODE	O

Maybe	O
my	O
real	O
question	O
is	O
"	O
why	O
isn't	O
`	O
melt	B-API
`	O
a	O
DataFrame	O
method	O
?	O

This	O
works	O
pretty	O
well	O
:	O
`	O
pd.melt	B-API
(	O
wide_df.reset_index()	O
,	O
"	O
subject	O
")`	O
,	O
but	O
it	O
feels	O
like	O
it	O
would	O
be	O
easier	O
to	O
read	O
as	O
chained	O
method	O
calls	O
that	O
can	O
be	O
read	O
in	O
linear	O
order	O
.	O

not	O
sure	O
why	O
their	O
isn't	O
a	O
``	O
melt	B-API
``	O
on	O
DataFrame	O
,	O
could	O
/	O
should	O
be	O
.	O

bool	O
operator	O
in	O
for	O
Timestamp	O
in	O
Series	O
does	O
not	O
work	O

Is	O
there	O
a	O
way	O
to	O
drop	O
columns	O
in	O
a	O
Dataframe	O
with	O
column	O
names	O
having	O
a	O
particular	O
letter	O
as	O
I	O
wasn't	O
able	O
to	O
find	O
any	O
information	O
on	O
this	O
?	O

I	O
want	O
to	O
drop	O
all	O
column	O
headers	O
having	O
the	O
letter	O
`	O
F	O
`	O
in	O
them	O
.	O

I	O
was	O
planning	O
on	O
doing	O
it	O
using	O
`	O
df.drop	B-API
([	O
df.columns	B-API
[[	O
column_names	O
]]]	O
,	O
axis=1	O
)`	O
,	O
but	O
there	O
are	O
so	O
many	O
that	O
I	O
was	O
wondering	O
if	O
there	O
is	O
an	O
easier	O
way	O
to	O
do	O
this	O
.	O

Rolling	B-API
argmax	B-API
in	O
pandas	O

I	O
have	O
a	O
pandas	O
TimeSeries	O
and	O
would	O
like	O
to	O
apply	O
the	O
argmax	B-API
function	O
to	O
a	O
rolling	B-API
window	O
.	O

However	O
,	O
due	O
to	O
casting	O
to	O
float	O
from	O
rolling_apply	B-API
,	O
if	O
I	O
apply	O
`	O
numpy.argmax()	B-API
`	O
,	O
I	O
only	O
obtain	O
the	O
index	O
of	O
the	O
slice	O
of	O
the	O
ndarray	O
.	O

Is	O
there	O
a	O
way	O
to	O
apply	O
a	O
rolling	B-API
argmax	B-API
to	O
a	O
Series	O
/	O
DataFrame	O
?	O

Here	O
is	O
a	O
work-around	O
,	O
essentially	O
doing	O
the	O
apply	B-API
'	O
manually	O
'	O
,	O
should	O
be	O
pretty	O
efficient	O
actually	O
.	O

You	O
could	O
do	O
a	O
`	O
shift	B-API
`	O
first	O
:	O
#CODE	O

Merge	O
csv's	O
with	O
some	O
common	O
columns	O
and	O
fill	O
in	O
Nans	O

pandas	O
-	O
resample	B-API
-	O
upsampling	O
before	O
downsampling	O

My	O
objective	O
is	O
to	O
resample	O
this	O
data	O
frame	O
with	O
a	O
fixed	O
time	O
window	O
(	O
e.g.	O
:	O
1	O
second	O
)	O
using	O
last	O
for	O
regularization	O
when	O
upsampling	O
and	O
the	O
mean	O
for	O
downsampling	O
.	O

Is	O
this	O
possible	O
at	O
all	O
using	O
pandas	O
resample	B-API
function	O
?	O

You	O
can't	O
mix	O
upsample	O
/	O
downsample	O
in	O
a	O
single	O
`	O
resample	B-API
`	O
operation	O
.	O

I'm	O
not	O
sure	O
why	O
the	O
order	O
of	O
operations	O
would	O
matter	O
to	O
you	O
as	O
long	O
as	O
you	O
get	O
the	O
desired	O
results	O
.	O

Thanks	O
for	O
your	O
answer	O
,	O
it	O
was	O
not	O
clear	O
to	O
me	O
that	O
you	O
had	O
to	O
make	O
multiple	O
calls	O
to	O
resample	B-API
.	O

You	O
can	O
then	O
concat	O
this	O
back	O
to	O
get	O
the	O
'	O
I	O
'	O
column	O
back	O
:	O
#CODE	O

Actually	O
setting	O
index_col=	O
'	O
I	O
'	O
when	O
reading	O
allows	O
to	O
avoid	O
the	O
concat	B-API
!	O

As	O
a	O
follow	O
up	O
to	O
this	O
post	O
,	O
I	O
would	O
like	O
to	O
concatenate	O
a	O
number	O
of	O
columns	O
based	O
on	O
their	O
index	O
but	O
I	O
am	O
encountering	O
some	O
problems	O
.	O

In	O
this	O
example	O
I	O
get	O
an	O
Attribute	O
error	O
related	O
to	O
the	O
map	B-API
function	O
.	O

Help	O
around	O
this	O
error	O
would	O
be	O
appreciated	O
as	O
would	O
code	O
that	O
does	O
the	O
equivalent	O
concatenation	O
of	O
columns	O
.	O

note	O
that	O
support	O
for	O
`	O
filter	B-API
(	O
None	O
,	O
iterable	O
)`	O
ceased	O
in	O
Python	O
3	O
,	O
need	O
to	O
do	O
`	O
filter	B-API
(	O
bool	O
,	O
iterable	O
)`	O
there	O

I	O
have	O
found	O
workaround	O
which	O
is	O
extremely	O
slow	O
due	O
to	O
the	O
"	O
in	O
python	O
"	O
apply	B-API
:	O
#CODE	O

How	O
to	O
drop	O
extra	O
copy	O
of	O
duplicate	O
index	O
of	O
Pandas	O
Series	O
?	O

So	O
how	O
to	O
drop	O
extra	O
duplicate	O
rows	O
of	O
series	O
,	O
keep	O
the	O
unique	O
rows	O
and	O
only	O
one	O
copy	O
of	O
the	O
duplicate	O
rows	O
in	O
an	O
efficient	O
way	O
?	O

One	O
way	O
would	O
be	O
using	O
`	O
drop	B-API
`	O
and	O
`	O
index.get_duplicates	B-API
`	O
:	O
#CODE	O

Not	O
totally	O
drop	O
the	O
duplicated	O
ones	O
.	O

You	O
can	O
groupby	B-API
the	O
index	O
and	O
apply	O
a	O
function	O
that	O
returns	O
one	O
value	O
per	O
index	O
group	O
.	O

@USER	O
sorry	O
,	O
"	O
arbitrary	O
"	O
of	O
length	O
len	B-API
(	O
s	O
)	O
:)	O
.	O

Below	O
is	O
my	O
snippet	O
:	O
import	O
pandas	O
as	O
pd	O
;	O
idx_tp	O
=	O
[(	O
'	O
600809	O
'	O
,	O
'	O
20061231	O
')	O
,	O
(	O
'	O
600809	O
'	O
,	O
'	O
20070331	O
')	O
,	O
(	O
'	O
600809	O
'	O
,	O
'	O
20070630	O
')	O
,	O
(	O
'	O
600809	O
'	O
,	O
'	O
20070331	O
')]	O
;	O
dt	B-API
=	O
[	O
'	O
demo	O
'	O
,	O
'	O
demo	O
'	O
,	O
'	O
demo	O
'	O
,	O
'	O
demo	O
']	O
;	O
idx	O
=	O
pd.MultiIndex.from_tuples	B-API
(	O
idx_tp	O
,	O
names	O
=	O
[	O
'	O
STK_ID	O
'	O
,	O
'	O
RPT_Date	O
'])	O
;	O
s	O
=	O
pd.Series	B-API
(	O
dt	B-API
,	O
index=idx	O
);	O
#	O
s.groupby	O
(	O
s.index	O
)	O
.first()	B-API
will	O
crash	O
on	O
my	O
machine	O

Edit	O
:	O
another	O
solution	O
which	O
is	O
faster	O
is	O
to	O
use	O
`	O
value_counts	B-API
`	O
(	O
and	O
normalize	B-API
):	O
#CODE	O

I	O
had	O
thought	O
this	O
was	O
more	O
concisely	O
written	O
as	O
a	O
`	O
resample	B-API
`	O
,	O
if	O
you	O
use	O
a	O
DatetimeIndex	B-API
:	O

len	B-API
(	O
Series.unique()	B-API
)	O
might	O
be	O
even	O
faster	O
.	O

Interestingly	O
,	O
len	B-API
(	O
Series.unique()	B-API
)	O
is	O
usually	O
much	O
faster	O
than	O
Series.nunique()	B-API
.	O

Next	O
,	O
these	O
3	O
columns	O
should	O
be	O
combined	O
into	O
one	O
column	O
-	O
the	O
mean	O
of	O
the	O
order	O
numbers	O
-	O
but	O
I	O
do	O
know	O
how	O
to	O
do	O
that	O
part	O
(	O
with	O
apply	B-API
and	O
axis=1	O
)	O
.	O

I	O
would	O
like	O
to	O
normalize	O
my	O
data	O
by	O
dividing	O
every	O
row	O
by	O
the	O
first	O
value	O
of	O
that	O
very	O
row	O
.	O

I	O
am	O
just	O
getting	O
stuck	O
on	O
"	O
setting	O
with	O
chained	O
indexing	O
"	O
and	O
setting	O
with	O
iloc	B-API
/	O
loc	B-API
/	O
ix	B-API
.	O

I	O
can't	O
figure	O
out	O
how	O
to	O
represent	O
this	O
using	O
iloc	B-API
,	O
loc	B-API
and	O
ix	B-API
.	O

Python	O
2.7	O
&	O
Pandas	O
:	O
How	O
to	O
replace	O
values	O
at	O
12:00	O
with	O
values	O
from	O
11:55	O
?	O

How	O
do	O
I	O
explicitly	O
say	O
'	O
replace	O
the	O
values	O
at	O
19:40	O
:	O
00	O
with	O
the	O
values	O
at	O
19:35	O
:	O
00	O
?	O

Python	O
merge	O
excel	O
documents	O
with	O
dynamic	O
columns	O

However	O
,	O
since	O
they	O
are	O
not	O
100%	O
identical	O
,	O
I	O
cannot	O
simply	O
merge	O
them	O
together	O
and	O
upload	O
it	O
into	O
a	O
database	O
without	O
messing	O
up	O
the	O
data	O
.	O

If	O
a	O
large	O
proportion	O
of	O
them	O
are	O
similar	O
,	O
and	O
this	O
is	O
a	O
one-off	O
operation	O
it	O
may	O
be	O
worth	O
your	O
while	O
coding	O
the	O
solution	O
for	O
the	O
majority	O
and	O
handling	O
the	O
other	O
documents	O
(	O
or	O
groups	O
of	O
them	O
if	O
they	O
are	O
similar	O
)	O
separately	O
.	O

Any	O
recommendations	O
to	O
a	O
db	O
that	O
would	O
allow	O
me	O
to	O
dump	O
a	O
few	O
thousand	O
excel	O
documents	O
and	O
then	O
create	O
join	O
queries	O
to	O
the	O
VIN	O
column	O
?	O

I	O
am	O
doing	O
a	O
transformation	O
on	O
a	O
variable	O
from	O
a	O
pandas	O
dataframe	O
and	O
then	O
I	O
would	O
like	O
to	O
replace	O
the	O
column	O
with	O
my	O
new	O
values	O
.	O

The	O
problem	O
seems	O
to	O
be	O
that	O
after	O
the	O
transformation	O
,	O
the	O
length	O
of	O
the	O
array	O
is	O
not	O
the	O
same	O
as	O
the	O
length	O
of	O
my	O
dataframe's	O
index	O
.	O

When	O
I	O
check	O
the	O
length	O
,	O
these	O
lengths	O
seem	O
to	O
disagree	O
.	O

The	O
len	B-API
(	O
array	O
)	O
says	O
it	O
is	O
2	O
but	O
when	O
I	O
call	O
the	O
stats.boxcox	B-API
it	O
says	O
it	O
is	O
50000	O
.	O

Print	O
out	O
`	O
len	B-API
(	O
df	O
)`	O
and	O
`	O
len	B-API
(	O
stats.boxcox	B-API
(	O
df.variable	O
))`	O
.	O

How	O
to	O
calculate	O
the	O
count	O
of	O
column	O
values	O
less	O
than	O
95	O
on	O
each	O
row	O
on	O
pandas	O
pivot	O
table	O

I	O
am	O
new	O
to	O
pandas	O
pivot	O
tables	O
,	O
how	O
to	O
get	O
the	O
count	O
of	O
column	O
values	O
less	O
than	O
95	O
for	O
a	O
row	O
on	O
pandas	O
pivot	O
table	O
#CODE	O

My	O
decorated	O
DataFrames	O
return	O
new	O
and	O
similarly	O
decorated	O
DataFrames	O
when	O
I	O
use	O
methods	O
such	O
as	O
copy	B-API
and	O
groupby.agg	B-API
.	O

I.e.	O
,	O
how	O
can	O
I	O
have	O
my	O
decorated	O
DataFrames	O
replace	O
the	O
stock	O
DataFrames	O
?	O

Still	O
not	O
getting	O
the	O
hang	O
of	O
pandas	O
,	O
I	O
am	O
attempting	O
to	O
join	O
two	O
data	O
frames	O
in	O
Pandas	O
using	O
merge	B-API
.	O

I	O
have	O
read	O
in	O
the	O
CSVs	O
into	O
two	O
data	O
frames	O
(	O
named	O
dropData	O
and	O
deosData	O
in	O
the	O
code	O
below	O
)	O
.	O

The	O
deosData	O
file	O
is	O
an	O
entire	O
year	O
s	O
worth	O
of	O
observations	O
that	O
I	O
am	O
trying	O
to	O
match	O
up	O
with	O
corresponding	O
entries	O
in	O
dropData	O
.	O

I	O
have	O
gone	O
through	O
the	O
documentation	O
for	O
the	O
merge	B-API
function	O
and	O
have	O
tried	O
the	O
following	O
code	O
in	O
various	O
iterations	O
,	O
so	O
far	O
I	O
have	O
only	O
been	O
able	O
to	O
have	O
a	O
blank	O
data	O
frame	O
with	O
correct	O
header	O
row	O
,	O
or	O
have	O
the	O
two	O
data	O
frames	O
merged	O
on	O
the	O
0	O
--	O
(	O
N-1	O
)	O
indexing	O
that	O
is	O
assigned	O
by	O
default	O
:	O

After	O
searching	O
on	O
SE	O
and	O
the	O
Doc	O
s	O
I	O
have	O
tried	O
resetting	O
the	O
index	O
,	O
ignoring	O
the	O
index	O
columns	O
,	O
copying	O
the	O
Date_Time	O
column	O
as	O
a	O
separate	O
index	O
and	O
trying	O
to	O
merge	O
on	O
the	O
new	O
column	O
,	O
I	O
have	O
tried	O
using	O
on=None	O
,	O
left_on	O
and	O
right_on	O
as	O
permutations	O
of	O
Date_Time	O
to	O
no	O
avail	O
.	O

I	O
have	O
checked	O
the	O
column	O
data	O
types	O
,	O
Date_Time	O
in	O
both	O
are	O
dtype	B-API
Objects	O
,	O
I	O
do	O
not	O
know	O
if	O
this	O
is	O
the	O
source	O
of	O
the	O
error	O
,	O
since	O
the	O
only	O
issues	O
I	O
could	O
find	O
searching	O
revolved	O
around	O
matching	O
different	O
dtypes	B-API
to	O
each	O
other	O
.	O

What	O
I	O
am	O
looking	O
to	O
do	O
is	O
have	O
the	O
two	O
data	O
frames	O
merge	O
where	O
the	O
two	O
'	O
Date_Time	O
'	O
columns	O
intersect	O
.	O

You	O
can	O
use	O
`	O
join	B-API
`	O
,	O
but	O
you	O
first	O
need	O
to	O
set	O
the	O
index	O
:	O
#CODE	O

You	O
can	O
also	O
do	O
`	O
groupby	B-API
(	O
...,	O
as_index=False	O
)`	O
,	O
though	O
buggy	O
with	O
apply	B-API
in	O
0.12	O
,	O
fixed	O
in	O
0.13	O
.	O

I've	O
converted	O
the	O
last	O
step	O
to	O
no	O
longer	O
be	O
a	O
loop	O
and	O
instead	O
save	O
directly	O
to	O
a	O
list	O
.	O

AFAIK	O
,	O
you	O
would	O
have	O
to	O
separate	O
the	O
two	O
parts	O
and	O
append	O
as	O
lists	O
since	O
the	O
columns	O
of	O
interest	O
are	O
different	O
and	O
converting	O
to	O
a	O
dictionary	O
would	O
include	O
the	O
`	O
NaN	O
`	O
s	O
otherwise	O
.	O

When	O
using	O
the	O
pure	O
XlsxWriter	O
I	O
can	O
apply	O
formats	O
to	O
cells	O
what	O
also	O
works	O
nice	O
.	O

Basically	O
how	O
would	O
I	O
apply	O
`	O
df	O
[	O
'	O
col1	O
']	O
.str	B-API
.contains	B-API
(	O
'	O
^	O
')`	O
to	O
an	O
entire	O
dataframe	O
at	O
once	O
and	O
filter	O
down	O
to	O
any	O
rows	O
that	O
have	O
records	O
containing	O
the	O
match	O
?	O

Pandas	O
:	O
apply	O
different	O
functions	O
to	O
different	O
columns	O

i	O
am	O
looking	O
to	O
apply	O
multiply	O
masks	O
on	O
each	O
column	O
of	O
a	O
pandas	O
dataset	O
(	O
respectively	O
to	O
it's	O
properties	O
)	O
in	O
python	O
.	O

how	O
can	O
i	O
apply	O
the	O
concat_mask	O
on	O
df	O
,	O
so	O
that	O
i	O
select	O
rows	O
,	O
in	O
which	O
all	O
Boolean	O
criteria	O
are	O
matched	O
(	O
are	O
True	O
)	O
?	O

.	O
Can	O
You	O
insert	O
that	O
into	O
your	O
answer	O
?	O

In	O
the	O
proper	O
code	O
i	O
actually	O
iterate	O
throw	O
all	O
columns	O
and	O
apply	O
various	O
of	O
diffenrent	O
conditions	O
to	O
mask	O
each	O
column	O
.	O

If	O
you	O
return	O
a	O
Series	O
of	O
the	O
(	O
split	O
)	O
location	O
,	O
you	O
can	O
merge	O
(	O
`	O
join	B-API
`	O
to	O
merge	O
on	O
index	O
)	O
the	O
resulting	O
DF	O
directly	O
with	O
your	O
value	O
column	O
.	O

If	O
I'm	O
not	O
mistaken	O
,	O
it	O
only	O
works	O
if	O
`	O
df	O
`	O
has	O
index	O
that	O
is	O
`	O
range	O
(	O
len	B-API
(	O
df	O
))`	O
,	O
right	O
?	O

`	O
join	B-API
`	O
is	O
shorthand	O
for	O
merging	O
on	O
index	O
with	O
both	O
frames	O
,	O
so	O
the	O
indices	O
need	O
only	O
be	O
consistent	O
(	O
which	O
it	O
will	O
be	O
here	O
as	O
the	O
apply	B-API
and	O
col	O
selection	O
don't	O
affect	O
it	O
)	O
.	O

How	O
to	O
resample	O
a	O
dataframe	O
with	O
different	O
functions	O
applied	O
to	O
each	O
column	O
?	O

@	O
Wes	O
McKinney	O
this	O
should	O
be	O
`	O
resample	B-API
`	O
in	O
0.8	O
,	O
isn't	O
it	O
?	O

Therefore	O
,	O
I	O
join	B-API
the	O
index	O
of	O
`	O
count_df	O
`	O
(	O
`	O
left_index=True	O
`)	O
with	O
the	O
`	O
CompanyName	O
`	O
column	O
of	O
`	O
df	O
`	O
(	O
`	O
right_on=	O
"	O
CompanyName	O
"`)	O
.	O

You	O
can	O
drop	O
the	O
extraneous	O
column	O
using	O
`	O
df.drop	B-API
`	O
:	O
#CODE	O

(	O
3	O
)	O
save	O
the	O
header	O
columns	O
for	O
concat	B-API
later	O
#CODE	O

(	O
5	O
)	O
output	O
:	O
concat	B-API
[	O
header	O
data	O
]	O
.	O
write	O
output	O
#CODE	O

groupby	B-API
after	O
concat	B-API
,	O
column	O
missing	O
in	O
the	O
group	O
mean	O

concat	B-API
two	O
dataframe	O
,	O
then	O
groupby	B-API
'	O
type	O
'	O
and	O
calculate	O
the	O
mean	O
,	O
columns	O
of	O
second	O
df	O
,	O
i.e.	O
d1~d10	O
,	O
showing	O
in	O
the	O
concat'ed	O
dataframe	O
but	O
not	O
in	O
the	O
grouped	O
mean	O
.	O

I	O
want	O
to	O
create	O
a	O
new	O
DataFrame	O
such	O
that	O
each	O
row	O
is	O
created	O
from	O
the	O
original	O
df	O
but	O
rows	O
with	O
loc	O
counts	O
greater	O
than	O
2	O
are	O
excluded	O
.	O

That	O
is	O
,	O
the	O
new	O
df	O
is	O
created	O
by	O
looping	O
through	O
the	O
old	O
df	O
,	O
counting	O
the	O
number	O
of	O
loc	O
rows	O
that	O
have	O
come	O
before	O
,	O
and	O
including	O
/	O
excluding	O
the	O
row	O
based	O
on	O
this	O
count	O
.	O

The	O
output	O
excludes	O
the	O
4th	O
row	O
in	O
the	O
original	O
df	O
because	O
its	O
loc	O
count	O
is	O
greater	O
than	O
2	O
(	O
i.e.	O
3	O
)	O
.	O

Also	O
,	O
be	O
careful	O
with	O
your	O
column	O
names	O
,	O
since	O
`	O
loc	O
`	O
clashes	O
with	O
the	O
`	O
.loc	B-API
`	O
method	O
.	O

So	O
you	O
get	O
a	O
string	O
back	O
:)	O
.	O

You	O
can	O
use	O
eval	B-API
(	O
""	O
[	O
1.5	O
,	O
2.5	O
,	O
3.5	O
]"")	O
,	O
but	O
I	O
hear	O
it's	O
bad	O
practice	O
.	O

You	O
can	O
map	O
your	O
lists	O
to	O
strings	O
by	O
using	O
`"	O
,	O
"	O
.join	B-API
(	O
your_list	O
)`	O
given	O
that	O
you	O
only	O
use	O
floats	O
.	O

merge	B-API
the	O
dataframe	O
on	O
ID	O
#CODE	O

The	O
`	O
merge	B-API
`	O
did	O
the	O
trick	O
,	O
but	O
I	O
thought	O
it	O
was	O
more	O
usefull	O
to	O
just	O
do	O
a	O
`	O
dfMerged.dropna()	O
`	O
after	O
the	O
merge	B-API
and	O
that	O
will	O
be	O
the	O
set	O
with	O
the	O
difference	O
.	O

yes	O
,	O
essentially	O
,	O
the	O
answer	O
was	O
really	O
about	O
the	O
`	O
merge	B-API
`	O
method	O
,	O
which	O
allows	O
you	O
to	O
sql-like	O
joins	O
.	O

Instead	O
,	O
I	O
get	O
an	O
error	O
telling	O
me	O
that	O
equiv	O
is	O
not	O
a	O
callable	O
function	O
.	O

Fair	O
enough	O
,	O
it's	O
a	O
dictionary	O
,	O
but	O
even	O
if	O
I	O
wrap	O
it	O
in	O
a	O
function	O
I	O
still	O
get	O
frustration	O
.	O

So	O
I	O
tried	O
to	O
use	O
a	O
map	B-API
function	O
that	O
seems	O
to	O
work	O
with	O
other	O
operations	O
,	O
but	O
it	O
also	O
is	O
defeated	O
by	O
use	O
of	O
a	O
dictionary	O
:	O
#CODE	O

ok	O
,	O
revised	O
the	O
answer	O
;	O
you	O
can	O
do	O
almost	O
anything	O
inside	O
the	O
apply	B-API
FYI	O

In	O
order	O
to	O
normalize	O
data	O
in	O
a	O
pandas	O
DataFrame	O
I	O
wrote	O
the	O
following	O
functions	O
:	O
#CODE	O

If	O
you	O
want	O
the	O
values	O
themselves	O
,	O
you	O
can	O
`	O
groupby	B-API
`	O
'	O
Column1	O
'	O
and	O
then	O
call	O
`	O
apply	B-API
`	O
and	O
pass	O
the	O
`	O
list	B-API
`	O
method	O
to	O
apply	O
to	O
each	O
group	O
.	O

You	O
could	O
`	O
groupby	B-API
`	O
on	O
`	O
Column1	O
`	O
and	O
then	O
take	O
`	O
Column3	O
`	O
to	O
`	O
apply	B-API
(	O
list	O
)`	O
and	O
call	O
`	O
to_dict	B-API
`	O
?	O

Pandas	O
-	O
How	O
can	O
I	O
set	O
rules	O
for	O
selecting	O
which	O
duplicates	O
to	O
drop	O

What	O
I	O
want	O
to	O
do	O
is	O
drop	O
the	O
values	O
that	O
have	O
the	O
same	O
index	O
(	O
date	O
time	O
)	O
,	O
but	O
I	O
want	O
to	O
make	O
a	O
rule	O
like	O
:	O

I	O
have	O
tried	O
using	O
groupby	B-API
and	O
apply	B-API
in	O
several	O
different	O
ways	O
but	O
I	O
cant	O
get	O
it	O
to	O
work	O
.	O

You	O
could	O
use	O
`	O
del	O
df	O
[	O
'	O
dist	O
']`	O
to	O
drop	O
the	O
dist	O
column	O
when	O
you	O
no	O
longer	O
need	O
it	O
.	O

Though	O
I	O
was	O
wondering	O
if	O
you	O
could	O
do	O
it	O
immediately	O
using	O
lambda	O
,	O
apply	B-API
and	O
groupby	B-API
.	O

I	O
am	O
sorry	O
I	O
am	O
trying	O
to	O
insert	O
code	O
into	O
comments	O
I	O
cant	O
do	O
it	O

All	O
I	O
am	O
doing	O
at	O
the	O
moment	O
is	O
loading	O
the	O
.csv	O
as	O
a	O
dataframe	O
and	O
then	O
writing	O
it	O
to	O
the	O
db	O
using	O
`	O
df.to_sql	B-API
(	O
table_name	O
,	O
engine	O
,	O
index=False	O
,	O
if_exists=	O
'	O
append	B-API
'	O
,	O
chunksize=1000	O
)`	O

I	O
want	O
to	O
transform	O
it	O
into	O
a	O
single	O
column	O
data	O
with	O
index	O
being	O
year-month	O
.	O

I	O
try	O
to	O
stack	O
my	O
original	O
data	O
but	O
it	O
becomes	O
a	O
time	O
series	O
,	O
which	O
has	O
the	O
year	O
mix	O
with	O
my	O
values	O
.	O

`	O
set_index	B-API
`	O
to	O
`	O
Year	O
`	O
first	O
,	O
and	O
then	O
`	O
stack	B-API
`	O
.	O

Can	O
pandas.concat	B-API
handle	O
non	O
float64	O
dtypes	B-API
?	O

You're	O
looking	O
for	O
an	O
[	O
`	O
expanding_mean	B-API
`]	O
(	O
#URL	O
)	O

You	O
can	O
always	O
`	O
pd.infer_freq	B-API
(	O
an_index	O
)`	O
if	O
you	O
need	O
to	O
re-infer	O
the	O
freqency	O
(	O
if	O
possible	O
)	O
.	O

actually	O
even	O
just	O
calling	O
`	O
df.isnull()	B-API
.sum()	B-API
`	O
takes	O
6.61ms	O

The	O
`	O
applymap	B-API
`	O
approach	O
consistently	O
seems	O
a	O
factor	O
of	O
2	O
or	O
so	O
faster	O
in	O
my	O
tests	O
,	O
but	O
YMMV	O
,	O
and	O
I'd	O
be	O
pretty	O
surprised	O
if	O
this	O
were	O
a	O
bottleneck	O
anyhow	O
.	O

Here	O
`	O
all_treatments.shape	O
=	O
(	O
53	O
,	O
12	O
)`	O
,	O
`	O
originalN	O
=	O
53	O
`	O
,	O
`	O
newN	O
=	O
64	O
`	O
,	O
`	O
all_treatments.loc	O
[	O
#URL	O
=	O
(	O
0	O
,	O
12	O
)`	O
,	O
`	O
all_treatments.loc	O
[	O
0	O
:	O
newrowcount	O
,	O
:]	O
.shape	B-API
=	O
(	O
12	O
,	O
12	O
)`	O
.	O

Try	O
using	O
.loc	B-API
[	O
row_index	O
,	O
col_indexer	O
]	O
=	O
value	O
instead	O
"	O

I	O
tried	O
`	O
df.hist()	B-API
`	O
.	O

Print	O
different	O
precision	O
by	O
column	O
with	O
pandas.DataFrame.to_csv()	B-API
?	O

If	O
so	O
,	O
I	O
read	O
in	O
those	O
same	O
fields	O
by	O
passing	O
`	O
dtype=float64	O
`	O
to	O
`	O
pd.read_csv	B-API
`	O
.	O

aha	O
drop_duplicates	B-API
,	O
didn't	O
know	O
about	O
that	O
one	O
,	O
thanks	O
!	O

More	O
generally	O
there	O
are	O
a	O
number	O
of	O
rolling-style	O
functions	O
to	O
handle	O
common	O
cases	O
and	O
a	O
`	O
rolling_apply	B-API
`	O
for	O
user	O
functions	O
.	O

of	O
`	O
df.loc	B-API
[	O
'	O
A	O
'	O
,	O
:]	O
`	O
.	O

`	O
.any()	B-API
`	O
returns	O
rows	O
of	O
boolean	O

`	O
DFdate.groupby	O
(	O
'	O
ID	O
')	O
.agg	B-API
(	O
lambda	O
col	O
:	O
col	O
[	O
col.notnull()	O
]	O
.head	B-API
(	O
1	O
))`	O

`	O
df	O
[	O
'	O
created_at	O
']	O
=	O
df	O
[	O
'	O
created_at	O
']	O
.apply	B-API
(	O
timeremap	O
)`	O

This	O
line	O
:	O
df	O
[	O
0	O
]=	O
df	O
[	O
0	O
]	O
.apply	B-API
(	O
pd.to_datetime	B-API
)	O
also	O
seems	O
to	O
be	O
wrong	O
it	O
seems	O
you	O
want	O
df	O
[	O
'	O
timestamp	O
']	O
=	O
df	O
[	O
'	O
timestamp	O
']	O
.	O

Out	O
[	O
26	O
]:	O
dtype	B-API
(	O
'	O
int64	O
')`	O
.	O

You're	O
looking	O
for	O
an	O
[	O
`	O
expanding_mean	B-API
`]	O
(	O
#URL	O
)	O

Clearly	O
I'm	O
missing	O
something	O
as	O
to	O
why	O
df.loc	B-API
[:	O
,	O
tuple	O
]	O
is	O
different	O
than	O
df	O
[	O
tuple	O
]	O
.	O

Try	O
`	O
.iloc	B-API
[	O
i-1	O
,	O
]`	O
and	O
`	O
.iloc	B-API
[	O
i	O
,	O
]`	O
instead	O
of	O
`	O
.iloc	B-API
[	O
i-1	O
,	O
:]	O
`	O
and	O
`	O
.iloc	B-API
[	O
i	O
,	O
:]	O
`	O
...	O

Is	O
there	O
a	O
way	O
to	O
write	O
percentages	O
in	O
Pandas	O
'	O
to_excel	B-API
?	O

For	O
example	O
,	O
`	O
X	O
[[	O
'	O
var2	O
'	O
,	O
'	O
var3	O
']]	O
.iloc	B-API
[[	O
0	O
,	O
1	O
]]	O
=	O
...	O

As	O
recommended	O
in	O
this	O
other	O
question	O
,	O
normally	O
I	O
would	O
skip	O
the	O
get_figure()	B-API
and	O
the	O
fig.savefig()	B-API
,	O
opting	O
instead	O
for	O
plt.savefig	B-API
,	O
but	O
I	O
am	O
making	O
multiple	O
figures	O
.	O

I'm	O
stuck	O
with	O
this	O
:	O
`	O
pd.concat	B-API
(	O
ndf	O
,	O
axis=1	O
)`	O

Note	O
#2	O
:	O
by	O
doing	O
an	O
implicit	O
"	O
right	O
=	O
1	O
-	O
left	O
"	O
,	O
I'm	O
assuming	O
that	O
no	O
ages	O
are	O
NaN	O
and	O
so	O
one	O
of	O
>	O
=	O
or	O
must	O
be	O
true	O
;	O
if	O
that's	O
not	O
certain	O
,	O
you	O
could	O
do	O
`	O
right	O
=	O
(	O
df	O
[	O
"	O
age	O
"]	O
.values	B-API
bins	O
[:	O
,	O
None	O
]	O
.T	B-API
.astype	B-API
(	O
int	O
)`	O
instead	O
.	O
)	O

I've	O
tried	O
reading	O
about	O
.loc	B-API
and	O
indexing	O
in	O
the	O
Pandas	O
documentation	O
and	O
failed	O
to	O
make	O
sense	O
of	O
it	O
.	O

Try	O
using	O
.loc	B-API
[	O
row_indexer	O
,	O
col_indexer	O
]	O
=	O
value	O
instead	O
`	O

Try	O
with	O
`	O
closed=	O
'	O
right	O
'`	O
on	O
the	O
call	O
to	O
`	O
date_range	B-API
`	O
.	O

However	O
,	O
on	O
a	O
10000	O
row	O
df	O
of	O
randn	B-API
,	O
this	O
is	O
almost	O
2000	O
times	O
faster	O
than	O
the	O
`	O
.apply	B-API
`	O
solution	O
above	O
:	O
3ms	O
vs	O
5850ms	O
.	O

Specify	O
float64	O
dtype	B-API
:	O
#CODE	O

Ah	O
,	O
yeah	O
,	O
I	O
just	O
re-wrote	O
the	O
answer	O
using	O
merge()	B-API
.	O

You	O
should	O
consider	O
using	O
`	O
pandas.melt	B-API
`	O
and	O
avoid	O
having	O
duplicate	O
columns	O
.	O

Note	O
that	O
`	O
df.filter	B-API
(	O
regex=	O
"	O
a	O
")`	O
is	O
equivalent	O
to	O
`	O
df	O
[[	O
'	O
a1	O
'	O
,	O
'	O
a2	O
'	O
,	O
'	O
a3	O
'	O
,	O
'	O
a4	O
']]`	O
#CODE	O

The	O
reason	O
is	O
because	O
internally	O
,	O
pandas	O
converts	O
a	O
regular	O
frequency	O
DatetimeIndex	B-API
to	O
PeriodIndex	O
to	O
hook	O
into	O
formatters	O
/	O
locators	O
in	O
pandas	O
,	O
and	O
currently	O
PeriodIndex	O
does	O
NOT	O
retain	O
timezone	O
information	O
.	O

Unfortunately	O
the	O
rolling_mean()	B-API
window	O
argument	O
only	O
accepts	O
integers	O
.	O

df_authors	O
=	O
pd.concat	B-API
([	O
df_addresses	O
,	O
df_authors	O
]	O
,	O
keys=	O
'	O
ISI_LOC	O
')	O

df.columns	O
=	O
df.iloc	B-API
[	O
idx_loc	O
]	O

Pandas	O
DataFrames	O
to_latex	B-API
:	O
how	O
to	O
fit	O
tables	O
on	O
a	O
page	O
?	O

@USER	O
--	O
`	O
np.diff	B-API
`	O
doesn't	O
seem	O
to	O
work	O
with	O
`	O
df.index	O
`	O
;	O
`	O
df.index.values	O
`	O
fixes	O
the	O
problem	O
though	O
...	O

Note	O
that	O
I	O
also	O
replaced	O
`	O
median()	B-API
`	O
by	O
`	O
last()	B-API
`	O
to	O
make	O
the	O
sorting	O
clearer	O
,	O
but	O
I	O
also	O
lose	O
entries	O
with	O
`	O
median()	B-API
`	O
.	O

How	O
to	O
modify	O
Pandas's	O
Read_html	B-API
user-agent	O
?	O

What	O
is	O
the	O
dtype	B-API
of	O
'	O
SMA_22	O
'	O
?	O

In	O
your	O
program	O
change	O
to	O
read_csv	B-API
.	O

I've	O
appended	O
your	O
comment	O
and	O
also	O
updated	O
with	O
the	O
newer	O
categorical	B-API
method	O
-	O
which	O
I	O
think	O
is	O
a	O
little	O
neater	O
:)	O
.	O

It	O
sounds	O
like	O
maybe	O
you	O
want	O
`	O
pandas.concat	B-API
`	O
?	O

well	O
,	O
pd.to_datetime	B-API
is	O
in	O
local	O
timezone	O
.	O

You	O
can	O
indeed	O
just	O
rely	O
on	O
`	O
.cummax()	B-API
`	O
with	O
`	O
.groupby()	B-API
`	O
and	O
`	O
.apply()	B-API
`	O
,	O
using	O
`	O
lambda	O
`	O
-	O
see	O
some	O
examples	O
:	O
#CODE	O

df.dtypes	B-API

So	O
now	O
,	O
the	O
dtypes	B-API
look	O
like	O
:	O
#CODE	O

iloc	B-API
should	O
be	O
in	O
0.11	O
btw	O
:	O
#URL	O

pd.read_csv	B-API
(	O
parse_dates	O
...	O
[	O
date_formatter	O
=])	O
returns	O
dtype	B-API
'	O
object	O
'	O
not	O
'	O
datetime64	O
'	O

This	O
is	O
a	O
string	O
I'm	O
getting	O
out	O
of	O
`	O
pandas.DataFrame.to_json()	B-API
`	O
,	O
putting	O
it	O
into	O
redis	O
,	O
getting	O
it	O
out	O
of	O
redis	O
elsewhere	O
,	O
and	O
trying	O
to	O
read	O
it	O
via	O
`	O
pandas.read_json()	B-API
`	O
:	O
#CODE	O

And	O
now	O
it's	O
getting	O
almost	O
2	O
times	O
faster	O
then	O
`	O
convert_objects	B-API
`	O
.	O

Is	O
this	O
page	O
also	O
documenting	O
Series.to_json()	B-API
in	O
addition	O
to	O
DataFrame.to_json()	B-API
?	O

The	O
DataFrame's	O
`	O
__getitem__	B-API
`	O
method	O
returns	O
a	O
different	O

You	O
can	O
check	O
`	O
.pivot	B-API
`	O
as	O
well	O
.	O

`	O
df.loc	B-API
[:	O
,	O
[	O
'	O
a	O
'	O
,	O
'	O
c	O
'	O
,	O
'	O
d	O
'	O
,	O
'	O
e	O
']]`	O

`	O
data.ix	O
[[	O
0	O
]	O
,	O
:]	O
.iloc	B-API
[:	O
,	O
0	O
]	O
.dtype	B-API
`	O
returns	O
the	O
right	O
dtype	B-API
,	O
but	O
`	O
data.ix	O
[[	O
]	O
,	O
:]	O
.iloc	B-API
[:	O
,	O
0	O
]	O
.dtype	B-API
`	O
does	O
not	O
.	O

I	O
am	O
appending	O
rows	O
to	O
a	O
`	O
HDFStore	B-API
`	O
with	O
`	O
append_as_multiple()	O
`	O
.	O

For	O
example	O
using	O
integers	O
in	O
a	O
DatetimeIndex	B-API
.	O

Also	O
,	O
reviewing	O
your	O
code	O
,	O
it	O
appears	O
that	O
you	O
are	O
specifying	O
your	O
`	O
iloc	B-API
`	O
columns	O
incorrectly	O
.	O

df.country	O
=	O
np.where	B-API
(	O
df.country	O
==	O
"	O
Australia	O
"	O
,	O
1	O
,	O
(	O
np.where	B-API
(	O
df.country	O
==	O
"	O
China	O
"	O
,	O
2	O
,	O
(	O
np.where	B-API
(	O
df.country	O
==	O
"	O
Japan	O
"	O
,	O
3	O
and	O
so	O
on	O
..	O
but	O
this	O
was	O
getting	O
way	O
long	O
.	O

That	O
was	O
supposed	O
to	O
be	O
`	O
dtype	B-API
`	O
not	O
`	O
dtypes	B-API
`	O
,	O
my	O
bad	O
,	O
sorry	O
.	O

Thanks	O
,	O
I	O
mistakenly	O
tried	O
using	O
.ix	B-API
[	O
'	O
False	O
']	O

pd.cut	B-API
worked	O
in	O
this	O
case	O
but	O
it's	O
good	O
to	O
learn	O
other	O
approaches	O
.	O

It	O
doesn't	O
seem	O
to	O
be	O
applying	O
ewma	B-API
on	O
[	O
2	O
,	O
4	O
]	O
or	O
[	O
2	O
,	O
2	O
,	O
4	O
]	O
.	O

To	O
avoid	O
this	O
`	O
.loc	B-API
`	O
syntax	O
is	O
used	O
.	O

`	O
_NDFrameIndexer	O
`'	O
s	O
`	O
__setitem__	B-API
`	O
is	O
a	O
different	O
story	O
.	O

I've	O
been	O
using	O
json_normalize	B-API
with	O
success	O
until	O
I	O
came	O
across	O
a	O
certain	O
json	O
.	O

Actually	O
I	O
was	O
imaging	O
there	O
may	O
be	O
something	O
like	O
`	O
pd.concat	B-API
([	O
#URL	O
...	O
)	O
.sum	B-API
(	O
axis=1	O
)	O
.....	O

Now	O
,	O
adding	O
the	O
cumsum	B-API
of	O
this	O
gets	O
you	O
the	O
result	O
you're	O
after	O
:	O
#CODE	O

And	O
`	O
df.groupby	B-API
(	O
'	O
age	O
')	O
.mean()	B-API
`	O
would	O
achieve	O
the	O
same	O
result	O
.	O

I	O
think	O
this	O
must	O
be	O
a	O
bug	O
with	O
MultiIndex.from_product()	B-API
because	O
the	O
long	O
version	O
,	O
using	O
MultiIndex.from_tuples()	B-API
works	O
:	O
#CODE	O

In	O
pandas	O
is	O
there	O
something	O
like	O
a	O
GroupBy.get_group	B-API
,	O
but	O
with	O
an	O
optional	O
default	O
value	O
?	O

Should	O
I	O
change	O
read_CSV	B-API
options	O
?	O

If	O
there	O
are	O
also	O
2-digit	O
variants	O
like	O
"	O
13	O
"	O
or	O
"	O
30	O
"	O
,	O
then	O
you	O
would	O
need	O
to	O
pass	O
a	O
more	O
complicated	O
regex	O
pattern	O
to	O
`	O
str.contains	B-API
`	O
.	O

dt_a1	O
=	O
dt_a.tolist()	O
#	O
yields	O
a	O
datetime	O
object	O
in	O
UTC	O
,	O
but	O
without	O
tzinfo	B-API

`	O
dtypes	B-API
:	O
float64	O
(	O
6	O
)	O
,	O
object	O
(	O
1	O
)`	O

I	O
was	O
trying	O
to	O
do	O
something	O
similar	O
with	O
`	O
ndimage.filters.generic_filter()	O
`	O
with	O
a	O
footprint	O
of	O
`	O
np.ones	B-API
(	O
consecutive	O
)`	O
and	O
playing	O
with	O
`	O
np.trim_zeros()	B-API
`	O
but	O
it	O
was	O
a	O
bit	O
far-fetched	O
.	O

`	O
.ix	B-API
`	O
and	O
`	O
.loc	B-API
`	O
are	O
equivalent	O
in	O
this	O
example	O
(	O
just	O
more	O
explicit	O
)	O
#CODE	O

This	O
looks	O
like	O
an	O
issue	O
with	O
spyder	O
being	O
unable	O
to	O
understand	O
the	O
dtype	B-API
,	O
not	O
sure	O
what	O
to	O
suggest	O
here	O
other	O
than	O
calling	O
`	O
print	O
`	O

resample()	B-API
is	O
expecting	O
:	O
if	O
isinstance	O
(	O
ax	O
,	O
DatetimeIndex	B-API
):	O
.....	O

poor	O
alignment	O
of	O
pandas.series	B-API
:	O
#URL	O

good	O
to	O
know	O
that	O
,	O
I'm	O
just	O
starting	O
with	O
pandas	O
,	O
i	O
will	O
read	O
the	O
doc	O
about	O
.loc	B-API
and	O
.iloc	B-API

Check	O
out	O
diff()	B-API
.	O

`	O
re.sub	O
`	O
is	O
a	O
resource	O
hog	O
compared	O
to	O
`	O
str.replace	B-API
`	O
.	O

Is	O
this	O
page	O
also	O
documenting	O
Series.to_json()	B-API
in	O
addition	O
to	O
DataFrame.to_json()	B-API
?	O

What	O
also	O
bothers	O
me	O
is	O
the	O
different	O
indexing	O
in	O
numpy.array	B-API
and	O
pandas.Panel	B-API
:	O
#CODE	O

Pandas	O
read_csv	B-API
not	O
recognizing	O
ISO8601	O
as	O
datetime	O
dtype	B-API

`	O
data=	O
pd.io.parsers.read_fwf	O
(	O
file	O
,	O
colspecs	O
=	O
([	O
79	O
,	O
81	O
]	O
,	O
[	O
87	O
,	O
90	O
])	O
,	O
header	O
=	O
None	O
,	O
dtype	B-API
=	O
{	O
0	O
:	O
np.str	O
,	O
1	O
:	O
np.str	O
}	O
)`	O

If	O
you're	O
on	O
0.15	O
,	O
then	O
it	O
has	O
new	O
and	O
improved	O
categorical	B-API
dtypes	B-API
that	O
were	O
only	O
introduced	O
fairly	O
recently	O
,	O
and	O
other	O
libraries	O
like	O
statsmodels	O
that	O
depend	O
on	O
pandas	O
probably	O
haven't	O
caught	O
up	O
yet	O
.	O

`	O
df.describe()	B-API
`	O
is	O
giving	O
different	O
results	O
compared	O
to	O
`	O
df.describe	B-API
`	O
.	O

What	O
is	O
the	O
``	O
dtype	B-API
``	O
of	O
your	O
'	O
datetime	O
'	O
column	O
?	O

We	O
can	O
do	O
this	O
using	O
`	O
np.r_	B-API
`	O
,	O
which	O
concatenates	O
arrays	O
:	O
#CODE	O

Have	O
you	O
tried	O
`	O
df.replace	B-API
(	O
'	O
SUPP	O
'	O
,	O
3.0	O
,	O
inplace=True	O
)`	O
?	O

It	O
sounds	O
like	O
what	O
you	O
are	O
looking	O
for	O
is	O
pd.rolling_mean	B-API
:	O
#CODE	O

How	O
can	O
I	O
access	O
multiple	O
columns	O
in	O
Pandas	O
0.15	O
DataFrame.resample	B-API
method	O
?	O

Note	O
,	O
I	O
added	O
1	O
to	O
the	O
`	O
pct_change()	B-API
`	O
method	O
because	O
it	O
computes	O
the	O
net	O
percent	O
change	O
.	O

df.dropna	B-API
(	O
subset	O
=[	O
'	O
tenant	O
']	O
,	O
inplace=True	O
)	O
works	O
.	O

`	O
pd.melt	B-API
`	O
it	O
is	O
!	O

I've	O
tried	O
appending	O
`	O
.any()	B-API
`	O
to	O
the	O
ends	O
of	O
the	O
`	O
contains()	B-API
`	O
statements	O
but	O
it	O
applies	O
the	O
`	O
Brand	O
`	O
label	O
to	O
every	O
row	O
.	O

I	O
think	O
you	O
can	O
just	O
write	O
`	O
df	O
[	O
"	O
y	O
"]	O
,	O
df	O
[	O
"	O
z	O
"]	O
=	O
zip	O
(	O
*df	O
[	O
"	O
x	O
"]	O
.apply	B-API
(	O
fn	O
))`	O
,	O
as	O
done	O
in	O
the	O
answer	O
to	O
[	O
this	O
question	O
]	O
(	O
#URL	O
)	O
.	O

``	O
pd.cut	B-API
``	O
is	O
often	O
used	O
for	O
this	O
as	O
well	O
(	O
and	O
you	O
can	O
specify	O
your	O
bins	O
)	O
,	O
see	O
here	O
:	O
#URL	O

@USER	O
is	O
this	O
solved	O
by	O
using	O
pd.concat	B-API
with	O
axis=1	O
i.e.	O
`	O
pd.concat	B-API
([	O
g	O
[	O
"	O
component	O
"]	O
.value_counts()	B-API
.unstack	B-API
(	O
1	O
)	O
,	O
g	O
[	O
"	O
gender	O
"]	O
.value_counts()	B-API
.unstack	B-API
(	O
1	O
)]	O
,	O
axis=1	O
)`	O
.	O

It	O
works	O
for	O
put()	B-API
but	O
not	O
for	O
append()	B-API
.	O

`	O
X	O
[	O
X.columns	O
-	O
Y.columns	O
]	O
.join	B-API
(	O
Y	O
)`	O

Try	O
`	O
pd.merge	B-API
(	O
A	O
,	O
A	O
,	O
...	O
)`	O
and	O
you'll	O
see	O
why	O
your	O
results	O
don't	O
work	O
.	O

Another	O
option	O
is	O
to	O
only	O
include	O
the	O
rows	O
that	O
have	O
a	O
value	O
:	O
"	O
df	O
[	O
df	O
[	O
'	O
FK_COL	O
']	O
.notnull()	B-API
]"	O
.	O

`	O
np.array	B-API
([	O
df	O
[	O
'	O
point	O
']])`	O
just	O
wraps	O
it	O
in	O
another	O
dimension	O
,	O
without	O
addressing	O
the	O
fundamental	O
object	O
dtype	B-API
issue	O
.	O

this	O
is	O
just	O
lnanenok's	O
answer	O
and	O
using	O
`	O
unstack()	B-API
`	O
to	O
make	O
it	O
more	O
readable	O
.	O
credit	O
should	O
go	O
to	O
lanenok	O
.	O

Atm	O
groupby.diff()	O
is	O
actually	O
doing	O
groupby.apply	B-API
(	O
pd.Series.diff	B-API
)	O
,	O
and	O
that's	O
usually	O
appears	O
to	O
be	O
slower	O
.	O

Because	O
to	O
me	O
it	O
seems	O
join()	B-API
handles	O
both	O
alignment	O
and	O
concatenation	O
in	O
one	O
go	O
.	O

That	O
wouldn't	O
help	O
here	O
because	O
I	O
am	O
using	O
merged_df.stack	O
(	O
0	O
)	O
.reset_index	B-API
(	O
1	O
)	O
in	O
a	O
pandas.merge	B-API
operation	O
....	O

yep	O
you	O
need	O
0.14.1	O
(	O
else	O
you	O
can	O
do	O
:	O
``	O
df.loc	B-API
[:	O
,	O
df.dtypes	B-API
!	O
=	O
'	O
object	O
']``)	O

And	O
then	O
calling	O
`	O
pd.merge	B-API
`	O
multiple	O
times	O
:	O
#CODE	O

The	O
final	O
result	O
is	O
equivalent	O
to	O
`	O
pd.Series	B-API
(	O
Counter	O
(	O
at_mentions.sum()	O
))`	O
.	O

`	O
sort_df	O
(	O
df	O
,	O
'	O
B	O
'	O
,	O
cmp	O
)	O
.drop_duplicates	B-API
(	O
'	O
A	O
'	O
,	O
take_last=True	O
)`	O
#CODE	O

@USER	O
OK	O
I	O
think	O
I	O
can	O
see	O
the	O
issue	O
with	O
my	O
code	O
,	O
`	O
df.ix	B-API
[((	O
df.mi.value_counts()	O
>	O
2	O
)	O
.index	B-API
)]	O
.dropna()	B-API
`	O
seems	O
to	O
give	O
you	O
what	O
you	O
want	O
.	O

Reindexing	O
produces	O
NaNs	O
because	O
they're	O
different	O
dtypes	B-API
.	O

I	O
don't	O
think	O
you	O
need	O
to	O
do	O
this	O
in	O
one	O
line	O
(	O
as	O
you	O
say	O
yourself	O
):	O
`	O
s	O
=	O
df	O
[	O
'	O
salary	O
']	O
;	O
df	O
[	O
'	O
salary	O
']	O
=	O
s.diff()	O
;	O
df	O
[	O
'	O
salary	O
']	O
.iloc	B-API
[	O
0	O
]	O
=	O
s.iloc	O
[	O
0	O
]`	O
.	O

Better	O
to	O
do	O
this	O
once	O
then	O
write	O
them	O
as	O
HDF5	O
files	O
;	O
they	O
come	O
already	O
blocked	O
by	O
dtypes	B-API
(	O
on	O
reading	O
)	O
.	O

I	O
guess	O
it	O
may	O
come	O
from	O
the	O
fact	O
that	O
`	O
pd.cut	B-API
`	O
is	O
optimized	O
to	O
work	O
on	O
columns	O
,	O
not	O
on	O
single	O
rows	O
...	O

Thanks	O
,	O
I	O
tried	O
something	O
similar	O
series1.divide	O
(	O
series2.reindex_like	O
(	O
series1+series2	O
)	O
.fillna	B-API
(	O
0	O
))	O
but	O
that	O
gave	O
a	O
slightly	O
different	O
result	O
.	O

I	O
noticed	O
that	O
`	O
DataFrame.to_html()	B-API
`	O
has	O
a	O
`	O
formatters	O
`	O
parameter	O
that	O
allows	O
one	O
to	O
do	O
just	O
that	O
,	O
mapping	O
different	O
formats	O
to	O
different	O
columns	O
.	O

But	O
`	O
df.iloc	B-API
[	O
5	O
]	O
[	O
'	O
B	O
']	O
=	O
'	O
three	O
'`	O
does	O
not	O
do	O
that	O
.	O

Hi	O
Matt	O
,	O
1	O
,	O
`	O
S4	O
`	O
is	O
the	O
`	O
numpy	O
`	O
`	O
dtype	B-API
`	O
for	O
`	O
string	O
`	O
.	O

pd.rolling_apply	B-API
(	O
df.exma	O
,	O
2	O
,	O
(	O
df.alpha	O
*	O
df.exma.shift	O
(	O
1	O
))	O
+	O
((	O
1	O
-	O
df.alpha	O
)	O
*	O
df.outperf	O
))	O

You	O
can	O
see	O
that	O
the	O
dtype	B-API
is	O
now	O
`	O
float32	O
`	O

When	O
putting	O
it	O
in	O
the	O
.ix	B-API
form	O
it	O
makes	O
much	O
more	O
sense	O
.	O

So	O
you	O
can	O
do	O
df2.shift	O
(	O
freq=	O
'	O
D	O
')	O
.stack	B-API
(	O
'	O
Trader	O
')	O
.	O

When	O
passing	O
`	O
aggfunc=	O
'	O
np.mean	B-API
'`	O
,	O
it	O
works	O
.	O

pandas	O
`	O
df.loc	B-API
[:	O
,	O
(	O
'	O
col_a	O
'	O
,	O
'	O
col_b	O
')]`	O

It	O
worked	O
both	O
your	O
way	O
and	O
this	O
one	O
:	O
`	O
df.to_csv	B-API
(	O
'	O
corr2.csv	O
'	O
,	O
sep=	O
'	O
\t	O
'	O
,	O
cols	O
=(	O
'	O
CO2abs	O
'	O
,	O
'	O
CO2corr	O
'))`	O

This	O
is	O
what	O
`	O
pct_change	B-API
`	O
is	O
doing	O
under	O
the	O
bonnet	O
.	O

s=	O
"	O
"	O
.join	B-API
(	O
x	O
)	O

As	O
I	O
mentioned	O
,	O
I	O
believe	O
that	O
the	O
bottleneck	O
is	O
not	O
Disk	O
I	O
/	O
O	O
but	O
rather	O
the	O
slowness	O
of	O
the	O
read_excel	B-API
package	O
.	O

Thanks	O
I	O
had	O
never	O
seen	O
this	O
before	O
:)	O
rolling_sum	B-API
could	O
also	O
be	O
useful	O
for	O
other	O
similar	O
problems	O
I	O
had	O
in	O
the	O
past	O
.	O

aha	O
drop_duplicates	B-API
,	O
didn't	O
know	O
about	O
that	O
one	O
,	O
thanks	O
!	O

I	O
tried	O
`	O
df.hist()	B-API
`	O
.	O

can	O
you	O
just	O
suggest	O
something	O
to	O
read	O
about	O
the	O
problem	O
`	O
to_datetime	B-API
`	O
,	O
or	O
when	O
do	O
I	O
need	O
it	O
??	O

Ok	O
,	O
I	O
tried	O
it	O
without	O
other	O
paratmeters	O
,	O
just	O
like	O
this	O
,	O
pd.merge	B-API
(	O
Up	O
[[	O
'	O
Gene_id	O
']]	O
,	O
annon	O
,	O
left_on=	O
'	O
Gene_id	O
'	O
,	O
right_on=	O
'	O
Gene_id	O
')	O
and	O
its	O
printing	O
out	O
the	O
header	O
from	O
df2	O
and	O
nothing	O
else	O
,	O
means	O
No	O
other	O
rows	O
..	O

import	O
pandas	O
as	O
pd	O
;	O
pd.concat	B-API
([	O
df1	O
,	O
s1	O
]);	O
Is	O
that	O
what	O
you're	O
looking	O
for	O
?	O

So	O
I	O
should	O
have	O
used	O
`	O
df.loc	B-API
`	O
**	O
not	O
**	O
`	O
df.iloc	B-API
`	O
.	O

Am	O
I	O
messing	O
up	O
`	O
pd.MultiIndex.from_product()	B-API
`	O
or	O
can	O
it	O
not	O
handle	O
being	O
passed	O
large	O
lists	O
?	O

I	O
print	O
out	O
the	O
objects	O
returned	O
by	O
`	O
read_csv	B-API
`	O
,	O
and	O
am	O
curious	O
about	O
the	O
differences	O
in	O
the	O
output	O
:	O

(	O
Note	O
:	O
this	O
is	O
wrong	O
-	O
bools	O
[	O
pd.isnull	B-API
(	O
df1	O
)	O
==	O
pd.isnull	B-API
(	O
df2	O
)]	O
=	O
False	O
)	O

IIUC	O
,	O
`	O
pivot_table	B-API
`	O
should	O
give	O
you	O
what	O
you	O
want	O
:	O
#CODE	O

i	O
guess	O
i'm	O
confused	O
.	O
are	O
these	O
so	O
big	O
that	O
using	O
`	O
iloc	B-API
`	O
won't	O
work	O
with	O
@USER	O
'	O
s	O
suggestions	O
?	O

I	O
am	O
particularly	O
talking	O
about	O
Pandas	O
version	O
0.11	O
as	O
I	O
am	O
busy	O
replacing	O
my	O
uses	O
of	O
.ix	B-API
with	O
either	O
.loc	B-API
or	O
.iloc	B-API
.	O

What	O
about	O
`	O
numpy.count_nonzero	B-API
`	O
:	O
#CODE	O

This	O
concats	O
correctly	O
:	O
`	O
df	O
=	O
pd.concat	B-API
([	O
room1	O
,	O
weather	O
]	O
,	O
axis=1	O
)`	O
.	O

to	O
ensure	O
the	O
conversion	O
uses	O
the	O
correct	O
dtype	B-API
.	O

dtypes	B-API
:	O
float64	O
(	O
1	O
)	O
,	O
object	O
(	O
3	O
)	O

However	O
,	O
adding	O
a	O
row	O
changes	O
dtype	B-API
to	O
float64	O
:	O
#CODE	O

Oh	O
,	O
I	O
didn't	O
know	O
about	O
`	O
diff()	B-API
`	O
.	O

Here	O
is	O
another	O
way	O
,	O
using	O
np.argmax	B-API
:	O
#CODE	O

I	O
thought	O
`	O
DF.apply	B-API
(	O
operator.itemgetter	O
(	O
-1	O
)	O
,	O
axis=1	O
)`	O
should	O
work	O
but	O
actually	O
it	O
won't	O
?	O

iloc()	B-API
works	O
.	O

freq_in_hertz	O
=	O
freqs	O
[	O
ind	O
[	O
ind1	O
]]	O
.mean()	B-API
`	O
.	O

```	O
In	O
[	O
15	O
]:	O
pd.to_timedelta	B-API
(	O
s.str.replace	O
(	O
'	O
hrs	O
'	O
,	O
'	O
h	O
'))	O

don't	O
have	O
a	O
usecase	O
handy	O
,	O
but	O
I'd	O
suspect	O
it's	O
:	O
`	O
df.loc	B-API
[(	O
df.index	O
[	O
'	O
a	O
']	O
<	O
something	O
&	O
df.index	O
[	O
'	O
b	O
']	O
<	O
another_thing	O
)]`	O

dtypes	B-API
are	O
different	O
:	O
#CODE	O

It	O
means	O
that	O
`	O
STORE	O
`	O
column	O
dtype	B-API
is	O
probably	O
float	O
,	O
try	O
`	O
df	O
[	O
'	O
STORE	O
']	O
=	O
df	O
[	O
'	O
STORE	O
']	O
.astype	B-API
(	O
int	O
)`	O
and	O
the	O
write	O
out	O
to	O
csv	O

I	O
think	O
`	O
get_value()	B-API
`	O
and	O
`	O
lookup()	B-API
`	O
is	O
faster	O
:	O
#CODE	O

IOW	O
:	O
`	O
first_two	O
=	O
df.iloc	B-API
[:	O
2	O
]`	O

If	O
I	O
understand	O
you	O
correctly	O
,	O
`	O
pivot_table	B-API
`	O
might	O
be	O
closer	O
to	O
what	O
you	O
need	O
:	O
#CODE	O

Can	O
you	O
do	O
a	O
df.dtypes	B-API
?	O

Now	O
the	O
`	O
date_range	B-API
`	O
behaviour	O
is	O
consistent	O
,	O
always	O
including	O
the	O
`	O
start	O
`	O
and	O
the	O
end	O
of	O
the	O
`	O
DatetimeIndex	B-API
`	O
always	O
=	O
`	O
end	O
`	O
.	O

`	O
.replace	B-API
(	O
'	O
[	O
\$	O
]'	O
,	O
`	O

I	O
am	O
contemplating	O
using	O
fromtxt	O
or	O
genfromtxt	B-API
to	O
read	O
the	O
file	O
in	O
,	O
then	O
pass	O
to	O
pandas	O

Also	O
I	O
know	O
this	O
must	O
be	O
possible	O
using	O
groupby.transform	B-API
.	O

The	O
only	O
potential	O
concern	O
is	O
the	O
change	O
of	O
`	O
dtype	B-API
`	O
,	O
`	O
x.dtype	O
`	O
is	O
`	O
dtype	B-API
(	O
'	O
float64	O
')`	O
,	O
while	O
`	O
y.dtype	O
`	O
is	O
`	O
dtype	B-API
(	O
'	O
object	O
')`	O
.	O

If	O
starting	O
from	O
`	O
idx	O
=	O
df	O
[[	O
"	O
col	O
A	O
"	O
,	O
"	O
col	O
B	O
"]]	O
.abs()	B-API
.idxmax	B-API
(	O
axis=1	O
)`	O

dtype	B-API
.	O

An	O
alternative	O
solution	O
,	O
it	O
uses	O
str.join	B-API
:	O
#CODE	O

of	O
the	O
dtype	B-API
:	O
#CODE	O

Here	O
it	O
is	O
:	O
{	O
dtype	B-API
(	O
'	O
int64	O
')	O
:	O
5074800	O
,	O
dtype	B-API
(	O
'	O
float64	O
')	O
:	O
1162129200	O
,	O
dtype	B-API
(	O
'	O
O	O
')	O
:	O
2369931600	O
}	O

I'm	O
not	O
completely	O
sure	O
I	O
understood	O
correctly	O
what	O
you	O
want	O
your	O
output	O
to	O
be	O
and	O
also	O
I	O
don't	O
think	O
using	O
`	O
dict	O
`	O
in	O
`	O
pandas.DataFrame	B-API
`	O
is	O
a	O
very	O
good	O
idea	O
in	O
general	O
.	O

I	O
did	O
it	O
using	O
df.groupby	B-API
(	O
df.index	O
)	O
.aggregate	B-API
(	O
np.sum	B-API
)	O
.	O

You	O
can	O
generate	O
the	O
counts	O
by	O
flattening	O
the	O
df	O
using	O
`	O
ravel	B-API
`	O
and	O
`	O
value_counts	B-API
`	O
,	O
from	O
this	O
you	O
can	O
construct	O
the	O
final	O
df	O
:	O
#CODE	O

Either	O
change	O
the	O
user	O
interface	O
so	O
that	O
`	O
filter_nan	O
`	O
is	O
an	O
additional	O
parameter	O
and	O
NaN	O
is	O
not	O
included	O
in	O
`	O
filter_list	O
`	O
,	O
or	O
else	O
check	O
`	O
pd.isnull	B-API
(	O
filter_list	O
)	O
.any()	B-API
`	O
and	O
handle	O
the	O
cases	O
accordingly	O
.	O

=	O
"	O
and	O
"	O
not_equal	B-API
"	O
in	O
pandas	O

Ouput	O
using	O
df.groupby	B-API
(	O
'	O
integer_id	O
')	O
.sum()	B-API
:	O
#CODE	O

(	O
There	O
is	O
both	O
`	O
Series.shift	B-API
`	O
and	O
`	O
DataFrame.shift	B-API
`	O
.	O
)	O
#CODE	O

df1.groupby	O
(	O
level=0	O
)	O
[	O
'	O
value	O
']	O
.apply	B-API
(	O
func	O
)`	O
let	O
me	O
know	O
if	O
this	O
works	O
for	O
you	O

@USER	O
is	O
this	O
solved	O
by	O
using	O
pd.concat	B-API
with	O
axis=1	O
i.e.	O
`	O
pd.concat	B-API
([	O
g	O
[	O
"	O
component	O
"]	O
.value_counts()	B-API
.unstack	B-API
(	O
1	O
)	O
,	O
g	O
[	O
"	O
gender	O
"]	O
.value_counts()	B-API
.unstack	B-API
(	O
1	O
)]	O
,	O
axis=1	O
)`	O
.	O

However	O
,	O
I	O
would	O
like	O
the	O
layout	O
to	O
be	O
generated	O
from	O
the	O
number	O
of	O
levels	O
in	O
the	O
categorical	B-API
conditioning	O
(	O
or	O
"	O
by	O
")	O
variable	O
(	O
s	O
)	O
.	O

Try	O
using	O
.loc	B-API
[	O
row_indexer	O
,	O
col_indexer	O
]	O
=	O
value	O
instead	O

@USER	O
i.e.	O
`	O
pd.concat	B-API
([	O
s1	O
,	O
s2	O
]	O
,	O
axis=1	O
)	O
.reset_index()	B-API
`	O

This	O
is	O
still	O
faster	O
then	O
using	O
np.loadtxt	B-API
(	O
iter	O
)	O

Does	O
your	O
dtype	B-API
happen	O
to	O
be	O
`	O
int32	O
`	O
?	O

I	O
don't	O
think	O
.shift()	B-API
works	O
in	O
this	O
case	O
as	O
'	O
rule3	O
'	O
is	O
a	O
calculated	O
column	O
with	O
each	O
row	O
value	O
dependant	O
on	O
the	O
previous	O
row	O
value	O
.	O

`	O
and	O
/	O
or	O
`	O
pd.rolling_std	B-API
=	O
...	O

dtypes	B-API
:	O
float64	O
(	O
4	O
)	O

`	O
df	O
[	O
'	O
Ck_SCR	O
']	O
=	O
df	O
[	O
'	O
Ck	O
']	O
.apply	B-API
(	O
getScoringFunction	O
(	O
Ck_dct	O
))`	O

Ideally	O
,	O
I	O
would	O
like	O
to	O
be	O
able	O
to	O
do	O
`	O
race1.index.hist()	O
`	O
or	O
`	O
race1.index.to_series()	O
.hist()	B-API
`	O
,	O
but	O
I	O
know	O
that	O
doesn't	O
work	O
.	O

Conversely	O
`	O
EArray	O
`	O
can	O
be	O
extended	O
with	O
the	O
`	O
.append()	B-API
`	O
method	O
.	O

Then	O
your	O
.ix	B-API
indexing	O
should	O
work	O
as	O
you'd	O
expect	O
.	O

This	O
is	O
a	O
typical	O
example	O
of	O
a	O
`	O
pivot_table	B-API
`	O
:	O
#CODE	O

I	O
tried	O
using	O
`	O
df.apply	B-API
(	O
lambda	O
x	O
:	O
isinstance	O
(	O
df	O
[	O
A	O
]	O
,	O
(	O
int	O
,	O
float	O
))	O
,	O
axis=1	O
)`	O
but	O
it	O
return	O
always	O
False	O
.	O

This	O
sounds	O
like	O
a	O
job	O
for	O
`	O
pivot_table	B-API
`	O
:	O
#CODE	O

Fixing	O
them	O
with	O
fillna	B-API
(	O
0	O
)	O
and	O
.loc	B-API
solved	O
it	O
.	O

`	O
X	O
=	O
np.vstack	B-API
(	O
X.sum	O
(	O
axis=1	O
))`	O

You	O
need	O
special	O
methods	O
for	O
that	O
,	O
and	O
this	O
is	O
what	O
.isnull()	B-API
is	O
about	O
.	O

When	O
I	O
run	O
the	O
line	O
returnsDf.iloc	O
[	O
1	O
:]	O
=	O
returnsDf.iloc	O
[	O
1	O
:]	O
.shift()	B-API
*	O
np.exp	B-API
(	O
rollReturnRandomDf.iloc	O
[	O
1	O
:])	O
the	O
code	O
runs	O
but	O
not	O
additional	O
output	O
is	O
produced	O
?	O

`	O
print	O
(	O
dt.date	B-API
(	O
2014	O
,	O
1	O
,	O
4	O
)	O
,	O
8	O
)	O
in	O
tmp.index	O
`	O
should	O
NOT	O
be	O
`	O
True	O
`	O

Just	O
out	O
of	O
curiosity	O
does	O
the	O
following	O
work	O
:	O
`	O
result	O
=	O
pandas.merge	B-API
(	O
left	O
,	O
right	O
,	O
how=	O
'	O
left	O
'	O
,	O
left_on=	O
left.columns	O
[	O
0	O
]	O
,	O
right_on=	O
right.columns	O
[	O
0	O
])`	O
?	O

`	O
inds	O
=	O
pd.isnull	B-API
(	O
df	O
)	O
.any	B-API
(	O
1	O
)	O
.nonzero()	B-API
[	O
0	O
]`	O
#CODE	O

Or	O
`	O
pd.concat	B-API
([	O
dat1	O
,	O
dat2	O
]	O
,	O
axis=1	O
)`	O
in	O
this	O
case	O
.	O

One	O
option	O
using	O
`	O
df.reindex	B-API
`	O
:	O
#CODE	O

Jahresgang	O
=	O
pd.DataFrame	B-API
(	O
Exceldata	O
,	O
dtype=	O
'	O
float	O
')	O

Do	O
this	O
:	O
df.applymap	B-API
(	O
lambda	O
x	O
:	O
x.astype	O
(	O
int	O
))	O
.to_csv	B-API
(	O
'	O
mycsv.csv	O
')	O

Pandas	O
module	O
read_csv	B-API
reads	O
file	O
within	O
Eclipse+pydev	O
while	O
fail	O
if	O
I	O
run	O
standalone	O

This	O
was	O
added	O
in	O
[	O
`	O
0.17.0	O
`]	O
(	O
#URL	O
)	O
scroll	O
a	O
bit	O
further	O
down	O
for	O
the	O
bit	O
on	O
`	O
drop_duplicates	B-API
`	O

df.Date	O
=	O
df.Date.apply	O
(	O
lambda	O
x	O
:	O
dt.datetime.strptime	O
(	O
x	O
,	O
'	O
%Y	O
/	O
%m	O
/	O
%d	O
')	O
.date()	B-API
)	O

I'm	O
not	O
sure	O
why	O
the	O
x_axis	O
is	O
formatted	O
like	O
that	O
in	O
pandas	O
,	O
it's	O
possible	O
your	O
2	O
line	O
issue	O
is	O
because	O
matplotlib	O
doesn't	O
understand	O
datetime64	O
dtype	B-API
correctly	O
,	O
see	O
this	O
:	O
#URL	O

Here	O
is	O
another	O
way	O
to	O
do	O
it	O
using	O
`	O
pd.get_dummies()	B-API
`	O
.	O

The	O
output	O
from	O
the	O
pandas.merge	B-API
is	O
:	O

Trying	O
to	O
think	O
of	O
a	O
way	O
leverage	O
applymap	B-API
for	O
this	O
issue	O
but	O
not	O
sure	O
how	O
to	O
implement	O
.	O

If	O
I	O
coerce	O
the	O
datetime64	O
to	O
dtype	B-API
object	O
then	O
it	O
aggregates	O
as	O
intended	O
.	O

I	O
did	O
`	O
df.astype	B-API
(	O
float32	O
)	O
.diff()	B-API
`	O
and	O
it	O
worked	O
.	O

I	O
think	O
they'll	O
be	O
imported	O
as	O
NaNs	O
,	O
then	O
,	O
so	O
dropna()	B-API
might	O
do	O
the	O
trick	O
.	O

When	O
running	O
timeit's	O
on	O
numpy	O
ndarrays	O
or	O
matrices	O
of	O
dtype	B-API
int64	O
,	O
you	O
see	O
the	O
same	O
performance	O
lag	O
.	O

However	O
,	O
I	O
have	O
tried	O
doing	O
`	O
df1	O
[	O
'	O
binned_a	O
']	O
=	O
pd.Series	B-API
(	O
pd.qcut	B-API
(	O
df1	O
[	O
'	O
a	O
']	O
,	O
4	O
))`	O
and	O
still	O
no	O
result	O
...	O

To	O
make	O
a	O
bit	O
more	O
explicit	O
what	O
Quazi	O
posted	O
:	O
`	O
drop_duplicates()	B-API
`	O
is	O
what	O
you	O
need	O
.	O

Same	O
dtypes	B-API
for	O
every	O
column	O
.	O

Hopefully	O
some	O
help	O
:	O
`	O
grouped.size()	O
.apply	B-API
(	O
lambda	O
x	O
:	O
x	O
>	O
1	O
)`	O
,	O
but	O
I'm	O
not	O
sure	O
how	O
to	O
do	O
this	O

The	O
way	O
I	O
got	O
it	O
to	O
work	O
anyway	O
was	O
by	O
doing	O
something	O
like	O
:	O
`	O
atom_col	O
=	O
'	O
*	O
'	O
.join	B-API
(	O
pd.Series	B-API
(	O
df	O
[	O
'	O
label	O
']))	O
.split	B-API
(	O
'	O
*	O
')	O
.unique()	B-API
`	O

The	O
`	O
.loc	B-API
`	O
syntax	O
for	O
extending	O
on	O
purpose	O
will	O
not	O
preserve	O
the	O
dtypes	B-API
in	O
a	O
multi-dtype	O
case	O
.	O

Specify	O
float64	O
dtype	B-API
:	O
#CODE	O

>>>	O
Why	O
is	O
python	O
in	O
the	O
"	O
for	O
i	O
in	O
df.iterrows()	B-API
:	O
"	O
still	O
executing	O
the	O
if-statement	O
on	O
the	O
whole	O
dataframe-level	O
instead	O
on	O
row-by-row	O
basis	O
.	O

or	O
`	O
.groupby	B-API
`	O
followed	O
by	O
`	O
.unstack	B-API
`	O
and	O
`	O
.fillna	B-API
`	O
:	O
#CODE	O

`'	O
,	O
'	O
.join	B-API
(	O
df	O
[	O
"	O
city	O
"]	O
.values	B-API
)`	O
--	O
this	O
will	O
return	O
a	O
comma-separated	O
string	O
.	O

You're	O
looking	O
for	O
`	O
df.replace	B-API
`	O

Can	O
I	O
do	O
this	O
with	O
a	O
rolling_apply	B-API
or	O
rolling_sum	B-API
?	O

@USER	O
oh	O
,	O
you're	O
looking	O
for	O
idxmax	B-API
so	O
:	O
`	O
df1.groupby	O
(	O
'	O
voting	O
')	O
.get_group	B-API
(	O
1	O
)	O
.mean()	B-API
.idxmax()	B-API
`	O
.	O

EDIT	O
:	O
Using	O
`	O
pd.merge	B-API
(	O
df1	O
,	O
df2	O
,	O
copy=False	O
)`	O
(	O
or	O
`	O
df1.merge	O
(	O
df2	O
,	O
copy=False	O
)`)	O
when	O
`	O
df1.dtype	O
!	O

`	O
df	O
[	O
'	O
max_bidhigh	O
']	O
=	O
pd.rolling_max	B-API
(	O
df	O
[	O
'	O
bidhigh	O
']	O
,	O
15	O
)	O
.shift	B-API
(	O
-14	O
)`	O
and	O

Then	O
you	O
can	O
reorder	O
the	O
columns	O
using	O
`	O
reindex_axis	B-API
`	O
:	O
#CODE	O

Pandas	O
-	O
Retrieve	O
Value	O
from	O
df.loc	B-API

or	O
simply	O
`	O
df.ix	B-API
[	O
0	O
,	O
'	O
A	O
']`	O

`	O
df.groupby	B-API
([	O
'	O
formation	O
'])	O
.aggregate	B-API
([	O
np.mean	B-API
,	O
np.size	O
])`	O
did	O
the	O
trick	O

SettingWitchCopyWarning	O
Pandas	O
using	O
.ix	B-API

Splitting	O
a	O
large	O
ndarray	B-API

As	O
of	O
version	O
`	O
0.17.0	O
`	O
you	O
can	O
do	O
this	O
using	O
`	O
dt.strftime	B-API
`	O
#CODE	O

Thanks	O
--	O
I	O
am	O
starting	O
to	O
think	O
that	O
I	O
can	O
do	O
this	O
with	O
`	O
pd.merge()	B-API
`	O
..	O

df	O
[	O
'	O
rolling_avg	O
']	O
=	O
pd.rolling_mean	B-API
(	O
df.price	O
,	O
n	O
,	O
1	O
)	O

in	O
viewlim_to_dt	B-API
(	O
self	O
)	O

Other	O
formulation	O
of	O
the	O
question	O
:	O
Why	O
is	O
python	O
in	O
the	O
"	O
for	O
i	O
in	O
df.iterrows()	B-API
:	O
"	O
still	O
executing	O
the	O
if-statement	O
on	O
the	O
whole	O
dataframe-level	O
instead	O
on	O
row-by-row	O
basis	O
.	O

`	O
df	O
[	O
'	O
exr_ln	O
']	O
=	O
df	O
[	O
'	O
exr	O
']	O
.map	B-API
(	O
math.log	O
)`	O

`	O
nx.set_edge_attributes	O
(	O
G	O
,	O
'	O
myattr	O
'	O
,	O
df	O
[	O
'	O
attribute	O
']	O
.astype	B-API
(	O
int	O
)	O
.to_dict()	B-API
)`	O
works	O
fine	O
but	O
then	O
`	O
nx.write_gexf()	O
`	O
complains	O
.	O

if	O
S	O
>	O
0	O
,	O
cost	O
=	O
(	O
M-A	O
)	O
.shift	B-API
(	O
1	O
)	O
*S	O

provides	O
integer	O
based	O
lookups	O
analogously	O
to	O
iloc	B-API

dtypes	B-API
:	O
object	O
(	O
3	O
)	O

I've	O
managed	O
to	O
read	O
them	O
into	O
numpy	O
using	O
numpy's	O
genfromtxt	B-API
,	O
but	O
I'm	O
not	O
sure	O
what	O
to	O
do	O
from	O
here	O
.	O

I've	O
explored	O
`	O
set_index()	B-API
`	O
,	O
`	O
replace()	B-API
`	O
,	O
`	O
to_datetime()	B-API
`	O
and	O
`	O
reindex()	B-API
`	O
and	O
possibly	O
some	O
others	O
but	O
non	O
seem	O
to	O
be	O
able	O
to	O
achieve	O
this	O
overwrite	O
.	O

`	O
df	O
[	O
'	O
timestamps	O
']	O
.tz_convert	B-API
(	O
'	O
US	O
/	O
Eastern	O
')`	O

Pandas	O
DataFrames	O
to_latex	B-API
:	O
how	O
to	O
fit	O
tables	O
on	O
a	O
page	O
?	O

df.groupBy	B-API
(	O
"	O
Type	O
")	O
.apply	B-API
(	O
lambda	O
x	O
:	O
(	O
x.Date	O
,	O
x.Number	O
))	O

have	O
you	O
tryed	O
`	O
print	O
type	O
(	O
float	O
(	O
'	O
-	O
1650.00	O
'	O
.replace	B-API
(	O
'	O
,	O
'	O
,	O
'')))`	O
?	O

You	O
can	O
do	O
this	O
using	O
`	O
date_range	B-API
`	O
easier	O
!	O

You	O
can	O
even	O
do	O
this	O
in	O
one	O
line	O
`	O
df	O
[	O
df	O
]	O
.stack()	B-API
.index	B-API
.tolist()	B-API
`	O
.	O

I	O
had	O
thought	O
of	O
shift()	B-API
and	O
diff()	B-API
,	O
but	O
realized	O
this	O
would	O
have	O
to	O
be	O
recursive	O
if	O
there	O
were	O
multiple	O
and	O
I	O
didn't	O
know	O
how	O
many	O
there	O
were	O
.	O

I'm	O
trying	O
to	O
generate	O
a	O
`	O
pandas.DateTimeIndex	B-API
`	O
with	O
a	O
samplefrequency	O
of	O
5120	O
Hz	O
.	O

I	O
recently	O
started	O
using	O
pandas	O
and	O
I	O
have	O
some	O
issue	O
regarding	O
date_range	B-API
.	O

for	O
passenger_index	O
,	O
passenger	O
in	O
df.iterrows()	B-API
:	O

To	O
expand	O
on	O
Tim's	O
idea	O
,	O
Example	O
:	O
`	O
df.drop	B-API
(	O
label	O
,	O
inplace=True	O
)`	O

`	O
object	O
`	O
is	O
the	O
correct	O
`	O
dtype	B-API
`	O
here	O
though	O
:	O
#URL	O
they	O
are	O
really	O
booleans	O
so	O
you	O
needn't	O
worry	O

It	O
is	O
also	O
used	O
like	O
this	O
in	O
methods	O
like	O
`	O
.mean	B-API
`	O
,	O
`	O
.prod	B-API
`	O
,	O
`	O
.any	B-API
`	O
,	O
`	O
.max	B-API
`	O
.	O

Then	O
its	O
simply	O
a	O
call	O
to	O
`	O
.stack()	B-API
`	O
and	O
some	O
basic	O
filtering	O
to	O
complete	O
.	O

`	O
df	O
[[	O
'	O
dservice	O
'	O
,	O
'	O
sservice	O
']]	O
=	O
df	O
[[	O
'	O
dport	O
'	O
,	O
'	O
sport	O
']]	O
.applymap	B-API
(	O
port_dict.get	O
)`	O

I	O
tried	O
using	O
the	O
pd.cut	B-API
:	O
#CODE	O

Note	O
instead	O
`	O
stacked.stack	O
(	O
level=1	O
)	O
.fillna	B-API
(	O
method=	O
'	O
ffill	B-API
')`	O

s=	O
"	O
"	O
.join	B-API
(	O
x	O
)	O

pandas.merge	B-API
is	O
adding	O
extra	O
rows	O

outage_by_hour_num.Time	O
=	O
pd.to_datetime	B-API
(	O
outage_by_hour_num.Time	O
)	O

`	O
MvT102	O
=	O
df.loc	B-API
[	O
df	O
[	O
'	O
MvT	O
']	O
==	O
102	O
]`	O

Change	O
in	O
PANDAS	O
.to_csv	B-API
default	O
formats	O
?	O

After	O
using	O
pd.get_dummies	B-API
,	O
it	O
has	O
300+	O
columns	O
,	O
for	O
example	O
#CODE	O

Have	O
a	O
general	O
question	O
on	O
assignments	O
with	O
indexing	O
/	O
slicing	O
using	O
.loc	B-API
.	O

The	O
`	O
df	O
[	O
'	O
A	O
']	O
[	O
10	O
]`	O
does	O
return	O
`'	O
a	O
'`	O
,	O
but	O
`	O
df	O
[	O
'	O
A	O
']	O
.ix	B-API
[	O
0	O
]`	O
throws	O
a	O
`	O
KeyError	O
:	O
0	O
`	O
.	O

I	O
ask	O
because	O
you	O
can	O
do	O
`	O
pd.read_clipboard()	B-API
`	O
in	O
`	O
pandas	O
`	O
and	O
there	O
is	O
this	O
question	O
:	O
#URL	O

You	O
need	O
to	O
do	O
an	O
assigment	O
like	O
`	O
df2	O
=	O
df.applymap	B-API
(	O
lambda	O
s	O
:	O
mymap.get	O
(	O
s	O
)	O
if	O
s	O
in	O
mymap	O
else	O
s	O
)`	O
.	O

Maybe	O
using	O
.ix	B-API
module	O
?	O

It	O
is	O
recommended	O
that	O
`	O
.loc	B-API
`	O
attribute	O
is	O
used	O
as	O
the	O
primary	O
label	O
based	O
access	O
method	O
to	O
avoid	O
problems	O
with	O
chained	O
assignment	O
.	O

(	O
And	O
in	O
case	O
you	O
are	O
wondering	O
,	O
the	O
`	O
ax.plot	O
`	O
stuff	O
is	O
equivalent	O
to	O
`	O
plt.plot	B-API
`	O
but	O
using	O
the	O
recommended	O
object-oriented	O
interface	O
.	O
)	O

Unfortunately	O
,	O
using	O
`	O
.ix	B-API
[	O
...	O
]`	O
still	O
seems	O
to	O
cause	O
nonsensical	O
axes-swapping	O
behavior	O
.	O

You	O
can	O
pass	O
a	O
delimiter	O
to	O
the	O
read_csv	B-API
method	O
but	O
in	O
your	O
case	O
,	O
since	O
the	O
delimiter	O
changes	O
by	O
file	O
,	O
you	O
want	O
to	O
pass	O
None	O
-	O
this	O
will	O
make	O
Pandas	O
auto-detect	O
the	O
correct	O
delimiter	O
.	O

Interestingly	O
,	O
the	O
`	O
object	O
`	O
dtype	B-API
in	O
pandas	O
is	O
a	O
NumPy	O
ndarray	B-API
which	O
holds	O
pointers	O
to	O
variable-length	O
string	O
items	O
.	O

@USER	O
btw	O
,	O
not	O
sure	O
why	O
,	O
but	O
`	O
read_fwf	B-API
`	O
doesn't	O
seem	O
to	O
support	O
`	O
dtype	B-API
`	O
even	O
though	O
it's	O
in	O
the	O
document	O
#URL	O

TypeError	O
:	O
map()	B-API
got	O
an	O
unexpected	O
keyword	O
argument	O
'	O
intializer	O
'`	O

So	O
are	O
you	O
looking	O
for	O
`	O
np.logical_or	B-API
((	O
df	O
>	O
0.4	O
)	O
,	O
(	O
df.shift()	B-API
>	O
=	O
0.3	O
))	O
.astype	B-API
(	O
int	O
)`	O
?	O

numpy.histogram	B-API

this	O
suggests	O
a	O
feature	O
:	O
``	O
.resample	B-API
(	O
'	O
D	O
'	O
,	O
how=	O
'	O
range	O
'	O
,	O
start=0	O
,	O
stop=3	O
)	O
.median()	B-API
``	O

Perform	O
read_clipboard	B-API
in	O
iPython	O
Qt	O
console	O
as	O
described	O
in	O
above	O
code	O
block	O

Ipython	O
:	O
`	O
pd.get_option	B-API
(	O
'	O
display.encoding	O
')	O
Out	O
[	O
141	O
]:	O
'	O
UTF-8	O
'`	O
.	O

force	O
datetime	O
conversion	O
,	O
coerce	O
datetime	O
dtype	B-API
,	O
with	O
read_table	B-API
in	O
pandas	O

do	O
this	O
:	O
``	O
df.ix	B-API
[	O
0	O
,	O
'	O
a	O
']	O
+=	O
1	O
``	O
.	O

I	O
tried	O
it	O
with	O
`	O
pd.read_clipboard()	B-API
`	O
from	O
the	O
OP	O
.	O

You	O
can	O
also	O
downsample	O
using	O
the	O
`	O
asof	B-API
`	O
method	O
of	O
`	O
pandas.DateRange	B-API
`	O
objects	O
.	O

